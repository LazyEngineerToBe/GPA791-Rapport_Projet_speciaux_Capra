
@book{tadokoro_rescue_2009,
	address = {Dordrecht ; New York},
	title = {Rescue robotics: {DDT} project on robots and systems for urban search and rescue},
	isbn = {978-1-84882-473-7 978-1-84882-474-4},
	shorttitle = {Rescue robotics},
	language = {en},
	publisher = {Springer},
	editor = {Tadokoro, Satoshi},
	year = {2009},
	note = {OCLC: ocn310400886},
	keywords = {Design and construction, Disaster Planning, Equipment and supplies, Künstliche Intelligenz, methods, Rescue work, Rescue Work, Robotics, Robots in search and rescue operations}
}

@book{nuchter_3d_2009,
	address = {Berlin ; Heidelberg},
	series = {{STAR} : {Springer} tracts in advanced robotics},
	title = {3D robotic mapping: the simultaneous localization and mapping problem with six degrees of freedom},
	isbn = {978-3-540-89883-2 978-3-540-89884-9},
	shorttitle = {3D robotic mapping},
	language = {English},
	number = {52},
	publisher = {Springer},
	author = {Nüchter, Andreas},
	year = {2009},
	note = {OCLC: ocn318362149},
	keywords = {Robotics, SLAM}
}

@book{carsten_behn_igor_zeidis_mechanics_2009,
	edition = {1},
	title = {Mechanics of {Terrestrial} {Locomotion}: {With} a {Focus} on {Non}-pedal {Motion} {Systems}},
	isbn = {3-540-88840-3 978-3-540-88840-6},
	url = {http://gen.lib.rus.ec/book/index.php?md5=7001EE35C59BF9ECD469AFE5D9E1B634},
	publisher = {Springer-Verlag Berlin Heidelberg},
	author = {Carsten Behn, Igor Zeidis, Klaus Zimmermann (auth.)},
	year = {2009}
}

@book{ceccarelli_designs_2015,
	title = {Designs and {Prototypes} of {Mobile} {Robots}},
	isbn = {978-0-7918-6047-2},
	url = {http://ebooks.asmedigitalcollection.asme.org/book.aspx?doi=10.1115/1.860472},
	language = {English},
	urldate = {2018-06-24},
	publisher = {ASME Press},
	author = {Ceccarelli, M. and Kececi, E. F.},
	year = {2015},
	doi = {10.1115/1.860472}
}

@incollection{ceccarelli_linkages_2015,
	title = {Linkages for {Leg} {Mechanisms}},
	isbn = {978-0-7918-6047-2},
	url = {http://ebooks.asmedigitalcollection.asme.org/content.aspx?bookid=1693&sectionid=109650182},
	abstract = {Walking robots are based on the mechanical structures of legs, in which mechanisms play an important role in functionality and performance characteristics. These robots have been developed with a wide variety of solutions over time. A short account of the history of using mechanisms in walking robots is presented in this paper, illust­rated through significant examples and an explanation of primary concepts, with the goal of stressing challenges for future development.},
	language = {en},
	urldate = {2018-06-24},
	booktitle = {Designs and {Prototypes} of {Mobile} {Robots}},
	publisher = {ASME Press},
	author = {Ceccarelli, Marco},
	collaborator = {Ceccarelli, M. and Kececi, E. F.},
	year = {2015},
	doi = {10.1115/1.860472_ch1}
}

@incollection{ceccarelli_mechanical_2015,
	title = {Mechanical {Design} {Challenges} in {Rescue} {Robot} {Prototyping}},
	isbn = {978-0-7918-6047-2},
	url = {http://ebooks.asmedigitalcollection.asme.org/content.aspx?bookid=1693&sectionid=109650188},
	abstract = {In rescue robotics, mobile robot platforms are used for search and rescue operations in the disaster zone. The design and realization of the robot from the idea to a working prototype require extensive knowledge and experience in mechanical, electrical and computer engineering. In the design and construction steps, mathematical calculations and manufacturing steps are carried out to realize the robot. Both digital and physical prototyping are explained and their differences and necessities are clarified. Later in the optimization stage risk analysis, functional conflicts, availability of materials, manufacturing capabilities and testing are considered and included in the design of a final prototype for better performance. This chapter explains the practice of rescue robot prototyping and the knowledge explained in this study can be applied to other mobile robotic fields.},
	language = {en},
	urldate = {2018-06-24},
	booktitle = {Designs and {Prototypes} of {Mobile} {Robots}},
	publisher = {ASME Press},
	author = {Kececi, Emin Faruk},
	collaborator = {Ceccarelli, M. and Kececi, E. F.},
	year = {2015},
	doi = {10.1115/1.860472_ch3}
}

@incollection{ceccarelli_networked_2015,
	title = {Networked {Control} for {Mobile} {Robots}},
	isbn = {978-0-7918-6047-2},
	url = {http://ebooks.asmedigitalcollection.asme.org/content.aspx?bookid=1693&sectionid=109650191},
	abstract = {As network technologies have developed, networked control became a main research focus in mobile robots, as well as in many other applications. In this chapter, the advantages and the applications of networked control mobile robots are summarized. Furthermore, the chapter presents the main problems and achievements facilitated by the interplay between networked control, communication and perception. Control over the networks has to deal with drawbacks brought by network communication, such as delays and data loss. The mobility of individual robots brings new challenges to communication and perception. Further study is still needed in the coverage and localization problems of mobile sensor networks. A brief review of our Novel Robotics System for Planetary Exploration (NOROS) and some related works, such as the study of group behaviors, optimal routing design and wireless sensor networks localization, are also presented.},
	language = {en},
	urldate = {2018-06-24},
	booktitle = {Designs and {Prototypes} of {Mobile} {Robots}},
	publisher = {ASME Press},
	author = {Ding, Xilun and Yang, Fan},
	collaborator = {Ceccarelli, M. and Kececi, E. F.},
	year = {2015},
	doi = {10.1115/1.860472_ch4}
}

@incollection{ceccarelli_exoskeletons_2015,
	title = {Exoskeletons and {Bipeds}},
	isbn = {978-0-7918-6047-2},
	url = {http://ebooks.asmedigitalcollection.asme.org/content.aspx?bookid=1693&sectionid=109650185},
	abstract = {Robotics is a field of interdisciplinary research, and the development­of its relevant disciplines has promoted its rapid progress in recent decades. Exoskeletons and bipeds, which are inspired by humans, have attracted many researchers. Exoskeletons, as the extenders of humans, can enhance a person’s strength, power and e­ ndurance. They are usually utilized in the medical field to provide assistance for disabled people. Bipeds are capable of assisting humans to do repeatable tasks or to operate tasks in dangerous environments. The significance of studying these two kinds of robots is not only to break through the limitations of human capability, but also to gain a better understanding of human body. This chapter focuses on the history and key technologies of exoskeletons and bipeds. Some representa­tive robots and mechanisms are described in detail.},
	language = {English},
	urldate = {2018-06-24},
	booktitle = {Designs and {Prototypes} of {Mobile} {Robots}},
	publisher = {ASME Press},
	author = {Huang, Qiang and Yu, Zhangguo},
	collaborator = {Ceccarelli, M. and Kececi, E. F.},
	year = {2015},
	doi = {10.1115/1.860472_ch2}
}

@incollection{ceccarelli_robot_2015,
	title = {Robot {Education} with {Mobile} {Robots}},
	isbn = {978-0-7918-6047-2},
	url = {http://ebooks.asmedigitalcollection.asme.org/content.aspx?bookid=1693&sectionid=109650197},
	abstract = {Even though the robot market size is still small at this moment, applied fields of robotics are gradually spreading, from the manufacturing industry to the third industry, as one of the important components to support an aging society. However; the consistent drop in birth rate in developed countries is resulting in a reduction in the number of talented students. This represents a great challenge for universities to motive young people to study science and technology. In this chapter, a survey of basic and advanced mobile robot platforms for educational purposes, at both undergraduate and graduate levels, is given. In particular, the main educational objectives with mobile robots are summarized, and two examples of mobile robot platforms for educational purposes are described, with an example of their actual use at the university level. Finally, research challenges for designing the next generation mobile robots for educational purposes are pointed out.},
	language = {en},
	urldate = {2018-06-24},
	booktitle = {Designs and {Prototypes} of {Mobile} {Robots}},
	publisher = {ASME Press},
	author = {Solis, Jorge},
	collaborator = {Ceccarelli, M. and Kececi, E. F.},
	year = {2015},
	doi = {10.1115/1.860472_ch6}
}

@techreport{office_of_the_chief_of_ordnance_catalog_1945,
	title = {Catalog of enemy ordnance materiel},
	url = {http://cgsc.contentdm.oclc.org/u?/p4013coll8,2758},
	abstract = {Volumes I and II are both contained in this document (German and Japanese). There is a practical reading and translation of Japanese characters, tables of basic key characters for Japanese ordnance, instructions for translating Japanese markings, an index to weapons by caliber for both forces, and an extensive index to both volumes. This document contains many pictures of weapons, ammunition, tanks, additional military vehicles and equipment, etc.},
	language = {English},
	author = {{Office of the Chief of Ordnance}},
	year = {1945}
}

@techreport{lederer_sensor_1981,
	address = {Gaithersburg, MD},
	title = {Sensor handbook for automatic test, monitoring, diagnostic, and control systems applications to military vehicles and machinery},
	url = {https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nbsspecialpublication615.pdf},
	abstract = {The Sensor Handbook is intended as a guide for those who design, specify, use, and test military automatic test equipment containing sensors. The handbook addresses measurands and principles of measurement, data acquisition, sensor calibration and testing, environmental considerations, stability, durability, reliability, and error assessment. Sensor manufacturers and sensor calibration and evaluation resources are included, as is an annotated bibliography. The handbook is based largely on the present, proved state-of-the-art. Possible future trends are briefly discussed. The handbook is addressed to the general engineer, system designer, or manager with an engineering background. It does not provide the highly detailed technical information needed by the measurement engineer, although ample references are included for further study.},
	language = {en},
	number = {NBS SP 615},
	urldate = {2018-06-24},
	institution = {National Bureau of Standards},
	author = {Lederer, Paul S},
	year = {1981},
	doi = {10.6028/NBS.SP.615}
}

@book{berendt_quieting:_1976,
	title = {Quieting: a practical guide to noise control},
	shorttitle = {Quieting},
	url = {http://archive.org/details/quietingpractica119bere},
	language = {eng},
	urldate = {2018-06-24},
	publisher = {National Bureau of Standards},
	author = {Berendt, Raymond D. and Corliss, Edith L. R. and Ojalvo, Morris S.},
	collaborator = {{NIST Research Library}},
	month = jul,
	year = {1976},
	keywords = {Noise control.}
}

@book{u.s._departement_of_the_army_fm_nodate,
	title = {{FM} 3-25.26 {Map} {Reading} and {Land} {Navigation}},
	url = {http://archive.org/details/milmanual-fm-3-25.26-map-reading-and-land-navigation},
	language = {English},
	urldate = {2018-06-24},
	author = {{\{U.S. Departement of the Army\}}},
	keywords = {map}
}

@book{howett_size_nodate,
	title = {Size of letters required for visibility as a function of viewing distance and observer visual acuity},
	url = {http://archive.org/details/sizeoflettersreq1180howe},
	language = {eng},
	urldate = {2018-06-24},
	publisher = {National Bureau of Standards (U.S.)},
	author = {Howett, Gerald L.},
	collaborator = {{NIST Research Library}},
	keywords = {Visual Acuity}
}

@techreport{franaszek_3d_2010,
	address = {Gaithersburg, MD},
	title = {3D imaging systems for manufacturing, construction, and mobility},
	url = {https://nvlpubs.nist.gov/nistpubs/Legacy/TN/nbstechnicalnote1682.pdf},
	language = {English},
	number = {NBS TN 1682},
	urldate = {2018-06-25},
	institution = {National Bureau of Standards},
	author = {Franaszek, Marek and Juberts, Maris and Lytle, Alan M and Cheok, Geralding S},
	year = {2010},
	doi = {10.6028/NIST.TN.1682}
}

@techreport{jacoff_guide_2014,
	address = {Gaithersburg, MD},
	type = {Guide},
	title = {Guide for {Evaluating}, {Purchasing}, and {Training} with {Response} {Robots} {Using} {DHS}-{NIST}-{ASTM} {International} {Standard} {Test} {Methods}},
	url = {https://www.nist.gov/sites/defaus/documents/el/isd/ks/DHS_NIST_ASTM_Robot_Test_Methods-2.pdf},
	language = {English},
	urldate = {2018-06-23},
	institution = {National Institute of Standards and Technology},
	author = {Jacoff, Adam},
	collaborator = {Messina, Elena and Huang, Hui-Min and Virts, Ann and Downs, Anthony and Norcross, Richard and Sheh, Raymond},
	month = 05,
	year = {2014},
	pages = {40}
}

@techreport{noauthor_standard_2016,
	address = {PA, USA},
	title = {Standard {Terminology} for {Evaluating} {Response} {Robot} {Capabilities}},
	url = {https://compass.astm.org/download/E2521.10463.pdf},
	language = {en},
	number = {E2521},
	urldate = {2018-06-24},
	institution = {ASTM International},
	year = {2016},
	pages = {3}
}

@techreport{noauthor_standard_2017,
	address = {PA, USA},
	title = {Standard {Test} {Method} for {Evaluating} {Response} {Robot} {Sensing}: {Visual} {Acuity}},
	url = {https://compass.astm.org/download/E2566.24498.pdf},
	language = {en},
	number = {E2566},
	urldate = {2018-06-24},
	institution = {ASTM International},
	year = {2017},
	pages = {16}
}

@techreport{noauthor_degrees_2013,
	type = {Code},
	title = {Degrees of protection provided by enclosures ({IP} code)},
	language = {English},
	number = {BS EN 60529},
	institution = {The British Standards Institution},
	year = {2013},
	pages = {48}
}

@misc{noauthor_hazchem_2018,
	title = {Hazchem},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Hazchem&oldid=830672503},
	abstract = {Hazchem () is a warning plate system used in Australia, Malaysia, New Zealand, India and the United Kingdom for vehicles transporting hazardous substances, and on storage facilities. The top-left section of the plate gives the Emergency Action Code (EAC) telling the fire brigade what actions to take if there's an accident. The middle-left section gives the UN Substance Identification Number describing the chemical. The lower-left section gives the telephone number that should be called if special advice is needed. The warning symbol at top-right indicates what danger the chemical presents. The bottom-right of the plate carries a company logo (the flower is a sample logo).
There is also a standard null Hazchem plate to indicate the transport of non-hazardous substances. The null plate does not include an EAC or substance identification.
The National Chemical Emergency Centre (NCEC) in the United Kingdom provides a Free Online Hazchem Guide.},
	language = {English},
	urldate = {2018-06-25},
	journal = {Wikipedia},
	month = mar,
	year = {2018},
	note = {Page Version ID: 830672503}
}

@techreport{noauthor_optique_2009,
	type = {Standard},
	title = {Optique ophtalmique - {Essai} d'acuité visuelle - {Optotype} normalisé et sa présentation},
	language = {German},
	number = {DIN EN 8596},
	institution = {DIN},
	month = oct,
	year = {2009},
	pages = {10}
}

@misc{noauthor_dont_2014,
	title = {Don't be misled by hazard ratings!},
	url = {http://www.lpslabs.com/sis/literature/HMIS3FlammabilityRatings_LPS.pdf},
	language = {English},
	urldate = {2018-06-25},
	publisher = {LPS Laboratories},
	year = {2014},
	keywords = {Hazmat, SIMDUT, GHS/SGH, NFPA 704}
}

@article{u.s._department_of_transportation_2016_nodate,
	title = {2016 {Emergency} {Response} {Guidebook}},
	issn = {N/A},
	url = {https://app.knovel.com/hotlink/toc/id:kpERG00031/emergency-response-guidebook/emergency-response-guidebook},
	language = {English},
	author = {{U.S. Department of Transportation}},
	keywords = {Hazmat}
}

@article{oconnell_collapse_nodate,
	title = {Collapse {Operations} for {First} {Responders}},
	issn = {978-1-59370-263-2},
	url = {https://app.knovel.com/hotlink/toc/id:kpCOFR0001/collapse-operations-first/collapse-operations-first},
	language = {English},
	author = {O’Connell, John}
}

@techreport{noauthor_standard_2017-1,
	address = {PA, USA},
	title = {Standard {Test} {Method} for {Evaluating} {Response} {Robot} {Capabilities}: {Mobility}: {Confined} {Area} {Obstacles}: {Gaps}},
	language = {en},
	number = {E2801},
	urldate = {2018-06-24},
	institution = {ASTM International},
	year = {2017},
	pages = {16}
}

@techreport{noauthor_standard_2017-2,
	address = {PA, USA},
	title = {Standard {Test} {Method} for {Evaluating} {Response} {Robot} {Capabilities}: {Mobility}: {Confined} {Area} {Obstacles}: {Hurdles}},
	language = {en},
	number = {E2802},
	urldate = {2018-06-24},
	institution = {ASTM International},
	year = {2017},
	pages = {16}
}

@techreport{noauthor_standard_2017-3,
	address = {PA, USA},
	title = {Standard {Test} {Method} for {Evaluating} {Response} {Robot} {Capabilities}: {Mobility}: {Confined} {Area} {Obstacles}: {Stairs}/{Landings}},
	language = {en},
	number = {E2804},
	urldate = {2018-06-24},
	institution = {ASTM International},
	year = {2017},
	pages = {16}
}

@techreport{noauthor_standard_2017-4,
	address = {PA, USA},
	title = {Standard {Test} {Method} for {Evaluating} {Response} {Robot} {Capabilities}: {Mobility}: {Maneuvering} {Tasks}: {Sustained} {Speed}},
	language = {en},
	number = {E2829},
	urldate = {2018-06-24},
	institution = {ASTM International},
	year = {2017},
	pages = {16}
}

@techreport{noauthor_standard_2017-5,
	address = {PA, USA},
	title = {Standard {Practice} for {Evaluating} {Response} {Robot} {Logistics}: {System} {Configuration}},
	language = {en},
	number = {E3132/E3132M},
	urldate = {2018-06-24},
	institution = {ASTM International},
	year = {2017},
	pages = {16}
}

@misc{serna_hazard_2012,
	title = {Hazard {Communications} ({HAZCOM}) {Symbols}},
	url = {https://udallas.edu/offices/documents/hazcommadesimple.pdf},
	language = {English},
	urldate = {2018-06-25},
	publisher = {University of Dallas, Facilities Departement},
	author = {Serna, Steve},
	year = {2012},
	keywords = {Hazmat, NFPA 704}
}

@book{astrom_feedback_2008,
	address = {Princeton},
	title = {Feedback systems: an introduction for scientists and engineers},
	isbn = {978-0-691-13576-2},
	shorttitle = {Feedback systems},
	language = {English},
	publisher = {Princeton University Press},
	author = {Åström, Karl J. and Murray, Richard M.},
	year = {2008},
	note = {OCLC: ocn183179623},
	keywords = {Feedback control systems}
}

@article{shuey_modeling_nodate,
	title = {Modeling and {Simulation} for a {Surf} {Zone} {Robot}},
	language = {en},
	author = {Shuey, Eric and Shuey, Mika},
	pages = {93}
}

@article{meisel_feature_nodate,
	title = {Feature based {Sensor} {Fusion} for {Victim} {Detection} in the {Rescue} {Robotics} {Domain}},
	language = {English},
	author = {Meisel, Alexander},
	pages = {90}
}

@book{lynch_modern_2017,
	address = {Cambridge, UK},
	title = {Modern robotics: mechanics, planning, and control},
	isbn = {978-1-107-15630-2 978-1-316-60984-2},
	shorttitle = {Modern robotics},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Lynch, Kevin M. and Park, Frank C.},
	year = {2017},
	note = {OCLC: ocn983881868},
	keywords = {Design and construction, Robotics, Control systems, Dynamics, Manipulators (Mechanism)}
}

@techreport{boyd_fire_2017,
	title = {Fire {Containment} {Drone}},
	abstract = {The goal of the fire containment drone project is to create a fire suppression system that can be easily integrated with an Unmanned Aerial Vehicle (UAV) to aid in the containment and control of offshore vessel fires. This system is designed to be an effective and reliable option for land fire-fighting personnel to operate at a safe distance to reduce potential risk and injury.},
	language = {English},
	institution = {Worcester Polytechnic Institute},
	author = {Boyd, William and Hood, Zachary and Lomi, John and St. Laurent, Chase and Young, Kile},
	year = {2017},
	pages = {95}
}

@misc{willows_garage_cheatsheet:_2018,
	title = {cheatsheet: {The} {ROS} {Cheatsheet} source},
	shorttitle = {cheatsheet},
	url = {https://github.com/ros/cheatsheet},
	language = {English},
	urldate = {2018-07-06},
	publisher = {Willows Garage},
	author = {{\{Willows Garage\}}},
	month = jun,
	year = {2018},
	note = {original-date: 2013-05-23T22:55:49Z},
	keywords = {Programming}
}

@misc{noauthor_robot_nodate,
	title = {Robot {Web} {Tools}},
	url = {http://robotwebtools.org/},
	urldate = {2018-07-06}
}

@inproceedings{toris_robot_2015,
	title = {Robot {Web} {Tools}: {Efficient} messaging for cloud robotics},
	isbn = {978-1-4799-9994-1},
	shorttitle = {Robot {Web} {Tools}},
	url = {http://ieeexplore.ieee.org/document/7354021/},
	doi = {10.1109/IROS.2015.7354021},
	abstract = {Since its ofﬁcial introduction in 2012, the Robot Web Tools project has grown tremendously as an opensource community, enabling new levels of interoperability and portability across heterogeneous robot systems, devices, and front-end user interfaces. At the heart of Robot Web Tools is the rosbridge protocol as a general means for messaging ROS topics in a client-server paradigm suitable for wide area networks, and human-robot interaction at a global scale through modern web browsers. Building from rosbridge, this paper describes our efforts with Robot Web Tools to advance: 1) human-robot interaction through usable client and visualization libraries for more efﬁcient development of front-end humanrobot interfaces, and 2) cloud robotics through more efﬁcient methods of transporting high-bandwidth topics (e.g., kinematic transforms, image streams, and point clouds). We further discuss the signiﬁcant impact of Robot Web Tools through a diverse set of use cases that showcase the importance of a generic messaging protocol and front-end development systems for human-robot interaction.},
	language = {en},
	urldate = {2018-07-06},
	publisher = {IEEE},
	author = {Toris, Russell and Kammerl, Julius and Lu, David V. and Lee, Jihoon and Jenkins, Odest Chadwicke and Osentoski, Sarah and Wills, Mitchell and Chernova, Sonia},
	month = sep,
	year = {2015},
	pages = {4530--4537}
}

@inproceedings{neuhaus_terrain_2009,
	title = {Terrain drivability analysis in 3D laser range data for autonomous robot navigation in unstructured environments},
	isbn = {978-1-4244-2727-7},
	url = {http://ieeexplore.ieee.org/document/5347217/},
	doi = {10.1109/ETFA.2009.5347217},
	abstract = {Three-dimensional laser range finders provide autonomous systems with vast amounts of information. However, autonomous robots navigating in unstructured environments are usually not interested in every geometric detail of their surroundings. Instead, they require real-time information about the location of obstacles and the condition of drivable areas.In this paper, we first present grid-based algorithms for classifying regions as either drivable or not. In a subsequent step, drivable regions are further examined using a novel algorithm which determines the local terrain roughness. This information can be used by a path planning algorithm to decide whether to prefer a rough, muddy area, or a plain street, which would not be possible using binary drivability information only.},
	urldate = {2018-07-08},
	publisher = {IEEE},
	author = {Neuhaus, Frank and Dillenberger, Denis and Pellenz, Johannes and Paulus, Dietrich},
	month = sep,
	year = {2009},
	keywords = {SLAM},
	pages = {1--4}
}

@inproceedings{yokokohji_guidelines_2006,
	title = {Guidelines for {Human} {Interface} {Design} of {Rescue} {Robots}},
	doi = {10.1109/SICE.2006.315163},
	abstract = {In this paper, we summarize the findings and know-hows in the individual developments and try to establish guidelines of human-interface design of rescue robots. These guidelines would be useful for the future development of rescue robots. Preliminary guidelines were set from some case studies of the DDT project and RoboCup Rescue. A trial towards the standardized interface is also shown},
	language = {English},
	booktitle = {2006 {SICE}-{ICASE} {International} {Joint} {Conference}},
	author = {Yokokohji, Y. and Tubouchi, T. and Tanaka, A. and Yoshida, T. and Koyanagi, E. and Matsuno, F. and Hirose, S. and Kuwahara, H. and Takemura, F. and Ino, T. and Takita, K. and Shiroma, N. and Kamegawa, T. and Hada, Y. and Osuka, K. and Watasue, T. and Kimura, T. and Nakanishil, H. and Horiguchi, Y. and Tadokoro, S. and Ohno, K.},
	month = oct,
	year = {2006},
	keywords = {Cameras, DDT project, Displays, Earthquakes, emergency services, environment map, graphical user interfaces, Graphical user interfaces, GUI, Guidelines, human interface design guidelines, Humans, image display, Man machine systems, Mechanical engineering, rescue robots, rescue systems, RoboCup Rescue, Robot vision systems, service robots, Urban Search and Rescue (USAR), Human Machine Interface},
	pages = {3455--3460}
}

@book{kern_engineering_2009,
	address = {Dordrecht ; New York},
	title = {Engineering haptic devices: a beginner's guide for engineers},
	isbn = {978-3-540-88247-3 978-3-540-88248-0},
	shorttitle = {Engineering haptic devices},
	language = {English},
	publisher = {Springer},
	editor = {Kern, Thorsten A.},
	year = {2009},
	keywords = {Haptic devices, Human-computer interaction, Systems engineering}
}

@book{budiyono_intelligent_2009,
	address = {Berlin},
	series = {Studies in computational intelligence},
	title = {Intelligent {Unmanned} {Systems}: {Theory} and {Applications}},
	isbn = {978-3-642-00263-2 978-3-642-00264-9},
	shorttitle = {Intelligent unmanned systems},
	number = {v. 192},
	publisher = {Springer},
	editor = {Budiyono, Agus and Riyanto, Bambang and Joelianto, Endra},
	year = {2009},
	note = {OCLC: ocn310400831},
	keywords = {Robotics}
}

@book{stachniss_robotic_2009,
	address = {Berlin},
	series = {Springer tracts in advanced robotics},
	title = {Robotic mapping and exploration},
	isbn = {978-3-642-01096-5 978-3-642-01097-2},
	language = {en},
	number = {Vol. 55},
	publisher = {Springer},
	author = {Stachniss, Cyrill},
	year = {2009},
	note = {OCLC: 845499168}
}

@article{lalonde_natural_2006,
	title = {Natural terrain classification using three-dimensional ladar data for ground robot mobility},
	volume = {23},
	issn = {15564959, 15564967},
	url = {http://doi.wiley.com/10.1002/rob.20134},
	doi = {10.1002/rob.20134},
	abstract = {In recent years, much progress has been made in outdoor autonomous navigation. However, safe navigation is still a daunting challenge in terrain containing vegetation. In this paper, we focus on the segmentation of ladar data into three classes using local three-dimensional point cloud statistics. The classes are: ”scatter” to represent porous volumes such as grass and tree canopy, ”linear” to capture thin objects like wires or tree branches, and ﬁnally ”surface” to capture solid objects like ground surface, rocks or large trunks. We present the details of the proposed method, and the modiﬁcations we made to implement it on-board an autonomous ground vehicle for real-time data processing. Finally, we present results produced from different stationary laser sensors and from ﬁeld tests using an unmanned ground vehicle.},
	language = {en},
	number = {10},
	urldate = {2018-07-08},
	journal = {Journal of Field Robotics},
	author = {Lalonde, Jean-François and Vandapel, Nicolas and Huber, Daniel F. and Hebert, Martial},
	month = oct,
	year = {2006},
	pages = {839--861}
}

@inproceedings{ohno_development_2009,
	title = {Development of 3D laser scanner for measuring uniform and dense 3D shapes of static objects in dynamic environment.},
	isbn = {978-1-4244-2678-2},
	url = {http://ieeexplore.ieee.org/document/4913337/},
	doi = {10.1109/ROBIO.2009.4913337},
	language = {English},
	urldate = {2018-07-09},
	publisher = {IEEE},
	author = {Ohno, Kazunori and Kawahara, Toyokazu and Tadokoro, Satoshi},
	month = feb,
	year = {2009},
	pages = {2161--2167}
}

@article{noauthor_comparison_2013,
	series = {{OSHA} {Quick} {Card}},
	title = {Comparison of {NFPA} 704 and {HazCom} 2012 {Labels}},
	language = {English},
	number = {OSHA 3678-08 2013},
	year = {2013}
}

@book{okane_gentle_2013,
	title = {A gentle introduction to {ROS}},
	isbn = {978-1-4921-4323-9},
	url = {http://www.cse.sc.edu/~jokane/agitr/},
	language = {English},
	publisher = {Independently published},
	author = {O'Kane, Jason M.},
	month = oct,
	year = {2013},
	note = {bibte[note=\{Available at {\textbackslash}url\{http://www.cse.sc.edu/{\textasciitilde}jokane/agitr/\}\}]}
}

@book{koubaa_robot_2016,
	address = {New York},
	series = {Studies in {Computational} {Intelligence}},
	title = {Robot {Operating} {System} ({ROS}): the complete reference ({Volume} 1)},
	volume = {1},
	isbn = {978-3-319-26052-5},
	shorttitle = {Robot {Operating} {System} ({ROS})},
	language = {en},
	number = {625},
	publisher = {Springer},
	editor = {Koubaa, Anis},
	year = {2016},
	note = {DOI 10.1007/978-3-319-26054-9}
}

@incollection{joseph_11._nodate,
	title = {11. {Designing} a {GUI} for a {Robot} {Using} {Qt} and {Python}},
	isbn = {978-1-78328-753-6},
	url = {https://app.knovel.com/hotlink/pdf/id:kt00UCAQZ3/learning-robotics-using/designing-gui-robot-using},
	language = {English},
	booktitle = {Learning {Robotics} {Using} {Python} - {Design}, {Simulate}, {Program}, and {Prototype} an {Interactive} {Autonomous} {Mobile} {Robot} from {Scratch} with the {Help} of {Python}, {ROS}, and {Open}-{CV}!},
	publisher = {Packt Publishing},
	author = {Joseph, Lentin}
}

@book{joseph_learning_2015,
	title = {Learning {Robotics} {Using} {Python} - {Design}, {Simulate}, {Program}, and {Prototype} an {Interactive} {Autonomous} {Mobile} {Robot} from {Scratch} with the {Help} of {Python}, {ROS}, and {Open}-{CV}!},
	isbn = {978-1-78328-753-6 978-1-68015-749-9},
	url = {https://app.knovel.com/hotlink/toc/id:kpLRUPDSP4/learning-robotics-using/learning-robotics-using},
	abstract = {If you are an engineer, a researcher, or a hobbyist, and you are interested in robotics and want to build your own robot, this book is for you. Readers are assumed to be new to robotics but should have experience with Python.},
	language = {English},
	publisher = {Packt Publishing},
	author = {Joseph, Lentin},
	year = {2015}
}

@techreport{u.s._army_materiel_command_engineering_1967,
	address = {Washington, DC},
	type = {Handbook},
	title = {Engineering {Design} {Handbook} - {Automotive} {Suspensions}},
	language = {English},
	number = {AMCP 706-356},
	institution = {United States Army Materiel Command},
	author = {{\{U.S. Army Materiel Command\}}},
	month = apr,
	year = {1967},
	pages = {459}
}

@book{koubaa_robot_2017,
	address = {Cham, Switzerland},
	series = {Studies in {Computational} {Intelligence}},
	title = {Robot {Operating} {System} ({ROS}): the complete reference ({Volume} 2)},
	volume = {2},
	isbn = {978-3-319-54926-2 978-3-319-54927-9},
	shorttitle = {Robot {Operating} {System} ({ROS})},
	url = {http://link.springer.com/10.1007/978-3-319-54927-9},
	language = {English},
	number = {707},
	urldate = {2018-07-11},
	publisher = {Springer International Publishing},
	editor = {Koubaa, Anis},
	year = {2017},
	doi = {10.1007/978-3-319-54927-9}
}

@book{chacon_pro_2018,
	edition = {Second edition},
	series = {The {Expert}'s {Voice}},
	title = {Pro {Git} - {Everything} you need to know about git},
	copyright = {Creative Commons Attribution-NonComercial-ShareAlike},
	shorttitle = {Pro {Git}},
	language = {English},
	publisher = {Apress},
	author = {Chacon, Scott and Straub, Ben},
	month = jun,
	year = {2018}
}

@inproceedings{m._lemmen_cacsd_2000,
	title = {{CACSD} for hydraulic cylinders},
	doi = {10.1109/CACSD.2000.900194},
	abstract = {Hydraulic drives such as synchronizing cylinders or differential cylinders have nonlinear plant dynamics. This paper demonstrates the advantage of using the computer algebra/symbolic computation system Maple to compute nonlinear controllers for the two different kind of plants treated here. Thus, we compute an exact linearizing controller for synchronizing cylinders with static state feedback using Maple. The controller shows good performance in experiments. Hydraulically driven differential cylinders, however, are not exact linearizable by static feedback with respect to the piston rod position as output. Thus, we design an input-output-linearizing controller for this kind of plant with the same software package. Again, this controller is tested in experiments and shows good performance},
	language = {English},
	booktitle = {{CACSD}. {Conference} {Proceedings}. {IEEE} {International} {Symposium} on {Computer}-{Aided} {Control} {System} {Design} ({Cat}. {No}.00TH8537)},
	author = {{M. Lemmen} and {M. Brocker}},
	year = {2000},
	keywords = {Control systems, Algebra, Hydraulics},
	pages = {101--106}
}

@inproceedings{sokolov_3d_2016,
	title = {3D modelling and simulation of a crawler robot in {ROS}/{Gazebo}},
	isbn = {978-1-4503-5213-0},
	url = {http://dl.acm.org/citation.cfm?doid=3029610.3029641},
	doi = {10.1145/3029610.3029641},
	language = {English},
	urldate = {2018-07-16},
	publisher = {ACM Press},
	author = {Sokolov, Maxim and Lavrenov, Roman and Gabdullin, Aidar and Afanasyev, Ilya and Magid, Evgeni},
	year = {2016},
	pages = {61--65}
}

@article{pecka_fast_2017,
	title = {Fast {Simulation} of {Vehicles} with {Non}-deformable {Tracks}},
	url = {http://arxiv.org/abs/1703.04316},
	abstract = {This paper presents a novel technique that allows for both computationally fast and sufficiently plausible simulation of vehicles with non-deformable tracks. The method is based on an effect we have called Contact Surface Motion. A comparison with several other methods for simulation of tracked vehicle dynamics is presented with the aim to evaluate methods that are available off-the-shelf or with minimum effort in general-purpose robotics simulators. The proposed method is implemented as a plugin for the open-source physics-based simulator Gazebo using the Open Dynamics Engine.},
	language = {English},
	urldate = {2018-07-16},
	journal = {arXiv:1703.04316 [cs]},
	author = {Pecka, Martin and Zimmermann, Karel and Svoboda, Tomáš},
	month = mar,
	year = {2017},
	note = {arXiv: 1703.04316},
	keywords = {Computer Science - Robotics, I.6.3}
}

@article{sander_bonirob_2015,
	title = {{BoniRob} {An} {Autonomous} {Mobile} {Platform} for {Agricultural} {Applications}},
	language = {English},
	author = {Sander, Slawomir and Robotics, Deepfield},
	year = {2015},
	pages = {25}
}

@article{madhavan_performance_2010,
	title = {Performance {Evaluation} and {Benchmarking} of {Robotic} and {Automation} {Systems} [{TC} {Spotlight}},
	volume = {17},
	issn = {1070-9932},
	url = {http://ieeexplore.ieee.org/document/5430368/},
	doi = {10.1109/MRA.2010.935811},
	language = {en},
	number = {1},
	urldate = {2018-07-16},
	journal = {IEEE Robotics \& Automation Magazine},
	author = {Madhavan, Raj and del Pobil, Angel and Messina, Elena},
	month = mar,
	year = {2010},
	pages = {120--122}
}

@article{jusuf_auto-navigation_nodate,
	title = {Auto-{Navigation} {For} {Robots}. {Implementation} of {ROS}},
	language = {English},
	author = {Jusuf, Fiki},
	pages = {32}
}

@book{lavalle_planning_2006,
	address = {Cambridge},
	title = {Planning {Algorithms}},
	isbn = {978-0-511-54687-7 978-0-521-86205-9},
	url = {https://www.cambridge.org/core/product/identifier/9780511546877/type/book},
	language = {en},
	urldate = {2018-07-16},
	publisher = {Cambridge University Press},
	author = {LaValle, Steven M.},
	year = {2006},
	doi = {10.1017/CBO9780511546877}
}

@incollection{koubaa_simulation_2016,
	address = {Cham},
	title = {Simulation of {Closed} {Kinematic} {Chains} in {Realistic} {Environments} {Using} {Gazebo}},
	volume = {625},
	isbn = {978-3-319-26052-5 978-3-319-26054-9},
	url = {http://link.springer.com/10.1007/978-3-319-26054-9_22},
	abstract = {Simulation is an integral part of the robo design process; it allows the designer to verify that the mechanical structure, sensors and software work together as intended. It can also serve as a collaboration platform for a team. Gazebo is a particularly attractive simulation platform as the physical behavior of the robot can be simulated in parallel with the ROS software that controls it. A lesser known feature of Gazebo is its ability to simulate closed kinematic chains. This is partly due to a lack of a well-established procedure for creating such simulations. This chapter describes in detail how robots with closed kinematic chains can be simulated in Gazebo. It explains how a robot model created with a computer-aided design (CAD) program such as SolidWorks can be exported to Gazebo so that closed kinematic chains are properly modeled, and how a realistic simulation environment can be generated. We provide detailed step-by-step examples that can be used by the reader to easily create new simulations using Gazebo and SolidWorks. SolidWorks was chosen as the CAD tool because it can partially export kinematic structures. Closed kinematic chains can then be relatively easily added to these exported structures so they can be used in Gazebo.},
	language = {en},
	urldate = {2018-07-16},
	booktitle = {Robot {Operating} {System} ({ROS})},
	publisher = {Springer International Publishing},
	author = {Bailey, Michael and Gebis, Krystian and Žefran, Miloš},
	editor = {Koubaa, Anis},
	year = {2016},
	doi = {10.1007/978-3-319-26054-9_22},
	pages = {567--593}
}

@inproceedings{koenig_design_2004,
	title = {Design and use paradigms for gazebo, an open-source multi-robot simulator},
	volume = {3},
	isbn = {978-0-7803-8463-7},
	url = {http://ieeexplore.ieee.org/document/1389727/},
	doi = {10.1109/IROS.2004.1389727},
	language = {English},
	urldate = {2018-07-16},
	publisher = {IEEE},
	author = {Koenig, N. and Howard, A.},
	year = {2004},
	pages = {2149--2154}
}

@inproceedings{noori_3d_2017,
	title = {On 3D simulators for multi-robot systems in {ROS}: {MORSE} or {Gazebo}?},
	isbn = {978-1-5386-3923-8},
	shorttitle = {On 3D simulators for multi-robot systems in {ROS}},
	url = {http://ieeexplore.ieee.org/document/8088134/},
	doi = {10.1109/SSRR.2017.8088134},
	abstract = {Realistically simulating a population of robots has been an important subject to the robotics community for the last couple of decades. Multi-robot systems are often challenging to deploy in the real world due to the complexity involved, and researchers often develop and validate coordination mechanisms and collaborative robotic behavior preliminarily in simulations. Thus, choosing a useful, ﬂexible and realistic simulator becomes an important task. In this paper, we overview several 3D multirobot simulators, focusing on those that support the Robot Operating System (ROS). We also provide a comparative analysis, discussing two popular open-source 3D simulators compatible with ROS – MORSE and Gazebo –, using a multi-robot patrolling application, i.e. a distributed security task, as a case study.},
	language = {en},
	urldate = {2018-07-16},
	publisher = {IEEE},
	author = {Noori, Farzan M. and Portugal, David and Rocha, Rui P. and Couceiro, Micael S.},
	month = oct,
	year = {2017},
	pages = {19--24}
}

@article{noauthor_jetson_nodate,
	title = {Jetson {TX}1/{TX}2 {Developer} {Kit} {Carrier} {Board} {Specification}},
	abstract = {This document contains recommendations and guidelines for Engineers to follow to create modules for the expansion connectors on the Jetson™ carrier board as well as understand the capabilities of the other dedicated interface connectors and associated power solutions on the platform.},
	language = {en},
	pages = {39}
}

@book{smith_car_2016,
	edition = {1},
	title = {The {Car} {Hacker}’s {Handbook}: {A} {Guide} for the {Penetration} {Tester}},
	isbn = {978-1-59327-703-1},
	shorttitle = {The {Car} {Hacker}’s {Handbook}},
	url = {http://gen.lib.rus.ec/book/index.php?md5=c962ae61ab381325b30211c72b3a2bfd},
	urldate = {2018-07-20},
	publisher = {No Starch Press},
	author = {Smith, Craig},
	year = {2016}
}

@techreport{thomas_kugelstadt_isolated_2010,
	title = {Isolated {CAN} {Reference} {Design}},
	language = {en},
	number = {SLLA298B},
	institution = {Texas Instruments},
	author = {{Thomas Kugelstadt}},
	month = may,
	year = {2010},
	pages = {3}
}

@article{kitano_robocup_2001,
	title = {{RoboCup} {Rescue}: {A} {Grand} {Challenge} for {Multiagent} and {Intelligent} {Systems}},
	volume = {22},
	copyright = {Copyright (c)},
	issn = {2371-9621},
	shorttitle = {{RoboCup} {Rescue}},
	url = {https://www.aaai.org/ojs/index.php/aimagazine/article/view/1542},
	doi = {10.1609/aimag.v22i1.1542},
	abstract = {Disaster rescue is one of the most serious social issues that involves very large numbers of heterogeneous agents in the hostile environment. The intention of the RoboCup Rescue project is to promote research and development in this socially significant domain at various levels, involving multiagent teamwork coordination, physical agents for search and rescue, information infrastructures, personal digital assistants, a standard simulator and decision-support systems, evaluation benchmarks for rescue strategies, and robotic systems that are all integrated into a comprehensive system in the future. For this effort, which was built on the success of the RoboCup Soccer project, we will provide forums of technical discussions and competitive evaluations for researchers and practitioners. Although the rescue domain is intuitively appealing as a large-scale multiagent and intelligent system domain, analysis has not yet revealed its domain characteristics. The first research evaluation meeting will be held at RoboCup-2001, in conjunction with the Seventeenth International Joint Conference on Artificial Intelligence (IJCAI-2001), as part of the RoboCup Rescue Simulation League and RoboCup/AAAI Rescue Robot Competition. In this article, we present a detailed analysis of the task domain and elucidate characteristics necessary for multiagent and intelligent systems for this domain. Then, we present an overview of the RoboCup Rescue project.},
	language = {en-US},
	number = {1},
	urldate = {2018-07-21},
	journal = {AI Magazine},
	author = {Kitano, Hiroaki and Tadokoro, Satoshi},
	month = mar,
	year = {2001},
	pages = {39}
}

@inproceedings{kitano_robocup:_1997,
	address = {New York, NY, USA},
	series = {{AGENTS} '97},
	title = {{RoboCup}: {The} {Robot} {World} {Cup} {Initiative}},
	isbn = {978-0-89791-877-0},
	shorttitle = {{RoboCup}},
	url = {http://doi.acm.org/10.1145/267658.267738},
	doi = {10.1145/267658.267738},
	urldate = {2018-07-21},
	booktitle = {Proceedings of the {First} {International} {Conference} on {Autonomous} {Agents}},
	publisher = {ACM},
	author = {Kitano, Hiroaki and Asada, Minoru and Kuniyoshi, Yasuo and Noda, Itsuki and Osawa, Eiichi},
	year = {1997},
	pages = {340--347}
}

@inproceedings{kitano_robocup_1999,
	title = {{RoboCup} {Rescue}: search and rescue in large-scale disasters as a domain for autonomous agents research},
	volume = {6},
	shorttitle = {{RoboCup} {Rescue}},
	doi = {10.1109/ICSMC.1999.816643},
	abstract = {Disaster rescue is one of the most serious social issue which involves very large numbers of heterogeneous agents in the hostile environment. RoboCup-Rescue intends to promote research and development in this socially significant domain by creating a standard simulator and forum for researchers and practitioners. While the rescue domain intuitively appealing as large scale multi-agent domains, it has not yet given through analysis on its domain characteristics. In this paper, we present detailed analysis on the task domain and elucidate characteristics necessary for multi-agent systems for this domain},
	booktitle = {1999 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics}, 1999. {IEEE} {SMC} '99 {Conference} {Proceedings}},
	author = {Kitano, H. and Tadokoro, S. and Noda, I. and Matsubara, H. and Takahashi, T. and Shinjou, A. and Shimada, S.},
	year = {1999},
	keywords = {Earthquakes, RoboCup Rescue, autonomous agents, Autonomous agents, Cities and towns, Collaboration, domain characteristics, Large-scale systems, mobile robots, Modeling, multi-agent systems, Multiagent systems, multiple agent systems, planning (artificial intelligence), Real time systems, strategy planning, Urban Search and Rescue (USAR), Kinematics, Artificial intelligence (AI)},
	pages = {739--743 vol.6}
}

@inproceedings{schwertfeger_using_2011,
	title = {Using a fiducial map metric for assessing map quality in the context of {RoboCup} {Rescue}},
	doi = {10.1109/SSRR.2011.6106762},
	abstract = {Mapping is an important task for mobile robots in general and for Safety, Security, and Rescue Robotics (SSRR) in particular. It is hence one core aspect which is evaluated in the RoboCup Rescue league. But assessing the quality of maps in a simple and efficient way is not trivial, especially if no detailed, complete ground truth data of the environment is available. A new approach on map evaluation is presented here. It makes use of artificial objects placed in the environment named “fiducials”. Using the known ground-truth positions and the positions of the fiducials identified in the map, a number of quality attributes can be assigned to that map. Depending on the application domain those attributes can weighed to compute a final score. Results are presented that are based on using this method during the RoboCup Rescue competition 2010 in Singapore where maps were generated by different teams in an maze populated with fiducials. Those maps are evaluated here and compared to a human judgment, showing the effectiveness of the fiducial approach.},
	booktitle = {2011 {IEEE} {International} {Symposium} on {Safety}, {Security}, and {Rescue} {Robotics}},
	author = {Schwertfeger, S. and Jacoff, A. and Pellenz, J. and Birk, A.},
	month = nov,
	year = {2011},
	keywords = {Mobile robots, RoboCup Rescue, mobile robots, Robot kinematics, Accuracy, fiducial map metric, ground-truth positions, map quality assessment, Measurement, path planning, quality attributes, Robot sensing systems, safety-security-rescue robotics, Singapore, Three dimensional displays, SLAM},
	pages = {208--214}
}

@inproceedings{kohlbrecher_community-driven_2012,
	title = {Community-driven development of standard software modules for search and rescue robots},
	isbn = {978-1-4799-0165-4 978-1-4799-0164-7 978-1-4799-0163-0},
	url = {http://ieeexplore.ieee.org/document/6523917/},
	doi = {10.1109/SSRR.2012.6523917},
	language = {English},
	urldate = {2018-07-21},
	publisher = {IEEE},
	author = {Kohlbrecher, Stefan and Petersen, Karen and Steinbauer, Gerald and Maurer, Johannes and Lepej, Peter and Uran, Suzana and Ventura, Rodrigo and Dornhege, Christian and Hertle, Andreas and Sheh, Raymond and Pellenz, Johannes},
	month = nov,
	year = {2012},
	pages = {1--2}
}

@inproceedings{skinner_robocup_2005,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Robocup {Rescue} {Simulation} {Competition}: {Status} {Report}},
	isbn = {978-3-540-35437-6 978-3-540-35438-3},
	shorttitle = {Robocup {Rescue} {Simulation} {Competition}},
	url = {https://link.springer.com/chapter/10.1007/11780519_63},
	doi = {10.1007/11780519_63},
	abstract = {This is the fifth anniversary of the Robocup Rescue Simulation Competitions and the tenth anniversary of the disaster that inspired the Competitions. This is a good time to take stock of what milestones have been achieved and what milestones we should be aiming for. Specifically, this paper looks at the goals that led to the establishment of the competition, the current status of the simulation platform and infrastructure, and finally suggests areas of the current simulation platform which should be improved and parts of the Robocup Rescue technical and social infrastructure which should be extended.},
	language = {en},
	urldate = {2018-07-21},
	booktitle = {{RoboCup} 2005: {Robot} {Soccer} {World} {Cup} {IX}},
	publisher = {Springer, Berlin, Heidelberg},
	author = {Skinner, Cameron and Barley, Mike},
	month = jul,
	year = {2005},
	pages = {632--639}
}

@techreport{hakam_saffour_implementing_2011,
	title = {Implementing {FULL} {CAN} bus in {PSoC}5 for electric vehicle development, {Step} by {Step} {Instructions}},
	url = {http://archive.org/details/ImplementingFullCanBusInPsoc5ForElectricVehicleDevelopmentStepBy},
	abstract = {Implementing FULL CAN bus in PSoC5 for electric vehicle development,
Step by Step Instructions},
	language = {English},
	urldate = {2018-07-23},
	institution = {Magdeburg University, IMS},
	author = {{Hakam Saffour}},
	month = apr,
	year = {2011},
	keywords = {CAN bus, PSoC},
	pages = {14}
}

@article{van_glabbeek_split_2017,
	title = {Split, {Send}, {Reassemble}: {A} {Formal} {Specification} of a {CAN} {Bus} {Protocol} {Stack}},
	volume = {244},
	issn = {2075-2180},
	shorttitle = {Split, {Send}, {Reassemble}},
	url = {http://arxiv.org/abs/1703.06569},
	doi = {10.4204/EPTCS.244.2},
	language = {en},
	urldate = {2018-07-23},
	journal = {Electronic Proceedings in Theoretical Computer Science},
	author = {van Glabbeek, Rob and Höfner, Peter},
	month = mar,
	year = {2017},
	pages = {14--52}
}

@techreport{corrigan_controller_2008,
	title = {Controller {Area} {Network} {Physical} {Layer} {Requirements}},
	abstract = {The multipoint bus structure and robust protocol of the High-Speed Controller Area Network (CAN), ISO 11898:1993, is finding widespread use in building automation, process control, and other industries. This paper provides the reader with the fundamentals of CAN technology, then focuses on the physical layer requirements.},
	language = {English},
	institution = {Texas Instruments},
	author = {Corrigan, Steve},
	year = {2008},
	pages = {15}
}

@article{monroe_basics_2013,
	title = {Basics of debugging the controller area network ({CAN}) physical layer},
	language = {English},
	number = {3Q},
	author = {Monroe, Scott},
	year = {2013},
	pages = {9}
}

@misc{sandia_national_laboratories_gemini_2013,
	title = {Gemini {Scout}: {Mine} {Rescue} {Vehicule}},
	language = {English},
	author = {{\{Sandia National Laboratories\}}},
	month = mar,
	year = {2013}
}

@article{ivaldi_tools_2014,
	title = {Tools for dynamics simulation of robots: a survey based on user feedback},
	shorttitle = {Tools for dynamics simulation of robots},
	url = {http://arxiv.org/abs/1402.7050},
	abstract = {The number of tools for dynamics simulation has grown in the last years. It is necessary for the robotics community to have elements to ponder which of the available tools is the best for their research. As a complement to an objective and quantitative comparison, difficult to obtain since not all the tools are open-source, an element of evaluation is user feedback. With this goal in mind, we created an online survey about the use of dynamical simulation in robotics. This paper reports the analysis of the participants' answers and a descriptive information fiche for the most relevant tools. We believe this report will be helpful for roboticists to choose the best simulation tool for their researches.},
	urldate = {2018-07-24},
	journal = {arXiv:1402.7050 [cs]},
	author = {Ivaldi, Serena and Padois, Vincent and Nori, Francesco},
	month = feb,
	year = {2014},
	note = {arXiv: 1402.7050},
	keywords = {Computer Science - Robotics}
}

@article{febbo_autonomous_nodate,
	title = {Autonomous {Vehicle} {Control} {Documentation}},
	language = {en},
	author = {Febbo, Huckleberry},
	pages = {86}
}

@incollection{koubaa_integration_2016,
	address = {Cham},
	title = {Integration and {Usage} of a {ROS}-{Based} {Whole} {Body} {Control} {Software} {Framework}},
	volume = {625},
	isbn = {978-3-319-26052-5 978-3-319-26054-9},
	url = {http://link.springer.com/10.1007/978-3-319-26054-9_21},
	abstract = {ControlIt! is a ROS-based high performance feedback control framework that enables Whole Body Control (WBC) algorithms to be implemented, instantiated, and integrated into ROS applications. It operates above individual joint controllers but below planners and takes a holistic view of the robot to achieve multiple simultaneous objectives. Such capabilities are particularly useful for highly redundant and multibranched robots like humanoids where the large number of degrees of freedom (DOFs) and intrinsic multi-tasking like reaching for an object while maintaining balance requires advanced feedback control strategies. ControlIt! provides two software abstractions, a compound task and a constraint set, that enables users to conﬁgure, use, and integrate whole body controllers. The compound task consists of prioritized tasks with controllers that operate in a relatively low dimensional space compared to the number of joints. The constraint set speciﬁes physical limits of the robot like points of contact with the environment and mechanical couplings between joints. ControlIt! comes with an implementation of the Whole Body Operational Space control (WBOSC) algorithm, one of the original WBC algorithms. Through prioritized null-space projection, WBOSC achieves each tasks’ objectives subjected to limitations from higher priority tasks and the constraint set. Using tasks and constraints, users can make high-DOF multi-branched robots execute sophisticated multi-objective and adaptive behaviors. This chapter presents ControlIt! and provides examples of advanced whole body behaviors it enables.},
	language = {en},
	urldate = {2018-07-24},
	booktitle = {Robot {Operating} {System} ({ROS})},
	publisher = {Springer International Publishing},
	author = {Fok, Chien-Liang and Sentis, Luis},
	editor = {Koubaa, Anis},
	year = {2016},
	doi = {10.1007/978-3-319-26054-9_21},
	pages = {535--563}
}

@incollection{almeida_realistic_2015,
	address = {Cham},
	title = {A {Realistic} {RoboCup} {Rescue} {Simulation} {Based} on {Gazebo}},
	volume = {9513},
	isbn = {978-3-319-29338-7 978-3-319-29339-4},
	url = {http://link.springer.com/10.1007/978-3-319-29339-4_27},
	abstract = {Since the ﬁrst demonstration of the Virtual Robot Competition, USARSim has been used as the simulation interface and environment. The underlying simulation platform, Unreal Engine, has seen three major upgrades (UT2004, UT3 and UDK). These upgrades required a whole new USARSim simulator to be built from scratch. Yet, between those versions the USARSim interface has not been modiﬁed, which made USARSim a stable platform for more than 10 years. This stability allowed developers to concentrate on their control and perception algorithms. This paper describes a new prototype of the USARSim interface; implemented as plugin to Gazebo, the simulation environment native to ROS. This plugin would facilitate a shift of the maintenance of the simulation environment to the Open Source Robotics foundation and attract new teams to the Virtual Robot Competition.},
	language = {en},
	urldate = {2018-07-25},
	booktitle = {{RoboCup} 2015: {Robot} {World} {Cup} {XIX}},
	publisher = {Springer International Publishing},
	author = {Shimizu, Masaru and Koenig, Nate and Visser, Arnoud and Takahashi, Tomoichi},
	editor = {Almeida, Luis and Ji, Jianmin and Steinbauer, Gerald and Luke, Sean},
	year = {2015},
	doi = {10.1007/978-3-319-29339-4_27},
	pages = {331--338}
}

@incollection{almeida_robust_2015,
	address = {Cham},
	title = {A {Robust} and {Calibration}-{Free} {Vision} {System} for {Humanoid} {Soccer} {Robots}},
	volume = {9513},
	isbn = {978-3-319-29338-7 978-3-319-29339-4},
	url = {http://link.springer.com/10.1007/978-3-319-29339-4_20},
	abstract = {This paper presents a vision system which is designed to be used by the research community in the Standard Platform League (http://www.tzi.de/spl) (SPL) and potentially in the Humanoid League (http://www.robocuphumanoid.org) (HL) of the RoboCup. It is realtime capable, robust towards lighting changes and designed to minimize calibration. We describe the structure of the processor along with major ideas behind object recognition. Moreover, we prove the beneﬁt of the proposed system by assessing recorded image data on the robot hardware. The vision system has already been successfully employed with the NAO robot by Aldebaran Robotics (http://www.aldebaran-robotics. com) in prior RoboCup competitions as well as several minor events.},
	language = {en},
	urldate = {2018-07-25},
	booktitle = {{RoboCup} 2015: {Robot} {World} {Cup} {XIX}},
	publisher = {Springer International Publishing},
	author = {Schwarz, Ingmar and Hofmann, Matthias and Urbann, Oliver and Tasse, Stefan},
	editor = {Almeida, Luis and Ji, Jianmin and Steinbauer, Gerald and Luke, Sean},
	year = {2015},
	doi = {10.1007/978-3-319-29339-4_20},
	pages = {239--250}
}

@article{kootbally_canonical_2016,
	title = {The {Canonical} {Robot} {Command} {Language} ({CRCL})},
	volume = {43},
	issn = {0143-991X},
	url = {https://doi.org/10.1108/IR-01-2016-0037},
	doi = {10.1108/IR-01-2016-0037},
	abstract = {Purpose This paper aims to describe an information model, the Canonical Robot Command Language (CRCL), which provides a high-level description of robot tasks and associated control and status information. Design/methodology/approach A common representation of tasks was used that is understood by all of the resources required for the job: robots, tooling, sensors and people. Findings Using CRCL, a manufacturer can quickly develop robotic applications that meet customer demands for short turnaround, enable portability across a range of vendor equipment and maintain investments in application development through reuse. Originality/value Industrial robots can perform motion with sub-millimeter repeatability when programmed using the teach-and-playback method. While effective, this method requires significant up-front time, tying up the robot and a person during the teaching phase.},
	number = {5},
	urldate = {2018-07-25},
	journal = {Industrial Robot},
	author = {Kootbally, Zeid and Schlenoff, Craig and Shackleford, William and Proctor, Frederick and Kramer, Thomas and Balakirsky, Stephen},
	month = aug,
	year = {2016},
	pages = {495--502}
}

@article{amorim_efcient_nodate,
	title = {Efﬁcient path planning of a mobile robot on rough terrain},
	abstract = {The following thesis adresses the problem of applying existing path planning technology to be used on rough terrains. Most path planning methods for mobile robots divide the environment in two areas – free and occupied – and restrict the path to lie within the free space.},
	language = {en},
	author = {Amorim, Diogo},
	pages = {9}
}

@article{mark_sauerwald_can_2014,
	series = {High-{Performance} {Analog} {Products}},
	title = {{CAN} bus, {Ethernet}, or {FPD}-{Link}: {Which} is best for automotive communications?},
	language = {English},
	number = {1Q},
	journal = {Analog Applications Journal},
	author = {{Mark Sauerwald}},
	year = {2014},
	note = {Texas Instruments},
	pages = {5}
}

@article{hegarty_rigel:_2016,
	title = {Rigel: {Flexible} {Multi}-rate {Image} {Processing} {Hardware}},
	volume = {35},
	issn = {0730-0301},
	shorttitle = {Rigel},
	url = {http://doi.acm.org/10.1145/2897824.2925892},
	doi = {10.1145/2897824.2925892},
	abstract = {Image processing algorithms implemented using custom hardware or FPGAs of can be orders-of-magnitude more energy efficient and performant than software. Unfortunately, converting an algorithm by hand to a hardware description language suitable for compilation on these platforms is frequently too time consuming to be practical. Recent work on hardware synthesis of high-level image processing languages demonstrated that a single-rate pipeline of stencil kernels can be synthesized into hardware with provably minimal buffering. Unfortunately, few advanced image processing or vision algorithms fit into this highly-restricted programming model. In this paper, we present Rigel, which takes pipelines specified in our new multi-rate architecture and lowers them to FPGA implementations. Our flexible multi-rate architecture supports pyramid image processing, sparse computations, and space-time implementation tradeoffs. We demonstrate depth from stereo, Lucas-Kanade, the SIFT descriptor, and a Gaussian pyramid running on two FPGA boards. Our system can synthesize hardware for FPGAs with up to 436 Megapixels/second throughput, and up to 297x faster runtime than a tablet-class ARM CPU.},
	number = {4},
	urldate = {2018-07-27},
	journal = {ACM Trans. Graph.},
	author = {Hegarty, James and Daly, Ross and DeVito, Zachary and Ragan-Kelley, Jonathan and Horowitz, Mark and Hanrahan, Pat},
	month = jul,
	year = {2016},
	keywords = {domain-specific languages, FPGAs, hardware synthesis, image processing, video processing},
	pages = {85:1--85:11}
}

@article{camargo-forero_towards_2018,
	title = {Towards high performance robotic computing},
	volume = {107},
	issn = {0921-8890},
	url = {http://www.sciencedirect.com/science/article/pii/S092188901830232X},
	doi = {10.1016/j.robot.2018.05.011},
	abstract = {Embedding a robot with a companion computer is becoming a common practice nowadays. Such computer is installed with an operatingsystem, often a Linux distribution. Moreover, Graphic Processing Units (GPUs) can be embedded on a robot, giving it the capacity of performing complex on-board computing tasks while executing a mission. It seems that a next logical transition, consist of deploying a cluster of computers among embedded computing cards. With this approach, a multi-robot system can be set as a High Performance Computing (HPC) cluster. The advantages of such infrastructure are many, from providing higher computing power up to setting scalable multi-robot systems. While HPC has been always seen as a speeding-up tool, we believe that HPC in the world of robotics can do much more than simply accelerating the execution of complex computing tasks. In this paper, we introduce the novel concept of High Performance Robotic Computing — HPRC, an augmentation of the ideas behind traditional HPC to fit and enhance the world of robotics. As a proof of concept, we introduce novel HPC software developed to control the motion of a set of robots using the standard parallel MPI (Message Passing Interface) library. The parallel motion software includes two operation modes: Parallel motion to specific target and swarm-like behavior. Furthermore, the HPC software is virtually scalable to control any quantity of moving robots, including Unmanned Aerial Vehicles, Unmanned Ground Vehicles, etc.},
	urldate = {2018-07-27},
	journal = {Robotics and Autonomous Systems},
	author = {Camargo-Forero, Leonardo and Royo, Pablo and Prats, Xavier},
	month = sep,
	year = {2018},
	keywords = {General-purpose computing mission, General-purpose computing robot, High performance robotic computing — HPRC, HPC cluster of robots, HPRC cluster, Parallel robotic computing node — PRCN},
	pages = {167--181}
}

@article{battistone_watch_2018,
	title = {Watch {Out}: {Embedded} {Video} {Tracking} with {BST} for {Unmanned} {Aerial} {Vehicles}},
	volume = {90},
	issn = {1939-8018, 1939-8115},
	shorttitle = {Watch {Out}},
	url = {http://link.springer.com/10.1007/s11265-017-1279-x},
	doi = {10.1007/s11265-017-1279-x},
	abstract = {The paper presents the development of a real time tracking system, named Watch Out, that is able to efficiently run on an Nvidia Jetson board mounted on a UAV (Unmanned Aerial Vehicle). The approach to long term video tracking implemented in Watch Out is named Best Structured Tracker (BST): a set of local trackers independently tracks patches of the original target in an online learning manner, while an outlier detection procedure filters out the less meaningful ones, and a resampling procedure allows to correctly reinitialise the trackers that have been filtered out. Performance of the tracking algorithm has been verified both on VOT2016 challenge datasets and in real situations using an Nvidia Jetson board mounted on a drone. Results show that the proposed system can track almost every possible target in real time.},
	language = {en},
	number = {6},
	urldate = {2018-07-27},
	journal = {Journal of Signal Processing Systems},
	author = {Battistone, Francesco and Petrosino, Alfredo and Santopietro, Vincenzo},
	month = jun,
	year = {2018},
	pages = {891--900}
}

@article{noauthor_telaire_nodate,
	title = {Telaire {T}6713 {Series} {Co}2 {Module}},
	language = {en},
	pages = {4}
}

@article{noauthor_ctre_nodate,
	title = {{CTRE} {Toolsuite} {Installation} {Guide}},
	language = {en},
	pages = {8}
}

@article{noauthor_can_2012,
	title = {{CAN} {Reference} {Guide}},
	language = {en},
	year = {2012},
	pages = {7}
}

@article{noauthor_jetson_nodate-1,
	title = {Jetson {TX}2/{TX}2i {OEM} {Product} {Design} {Guide}},
	abstract = {This document contains recommendations and guidelines for Engineers to follow to create a product that is optimized to achieve the best perf ormance f rom the common interf aces supported by the NVIDIA® Jetson™ TX2/TX2i Systemon-Module (SOM).},
	language = {en},
	pages = {103}
}

@techreport{bailey_remote_nodate,
	title = {Remote {Cable} {Gantry}},
	language = {en},
	institution = {California Polytechnic State University},
	author = {Bailey, Allen},
	pages = {51}
}

@techreport{murphy_rogue_2017,
	title = {Rogue {Rotary} : {Modular} {Robotic} {Rotary} {Joint} {Design}},
	institution = {California Polytechnic State University},
	author = {Murphy, Sean and Triplet, Jacob and Riessen, Tyler},
	year = {2017},
	pages = {81}
}

@techreport{mackinnon_urban_nodate,
	title = {Urban {Search} and {Rescue} {Robot}},
	abstract = {The aim of the project was to design and manufacture a functional urban search and rescue robot to revive the competitiveness of the Warwick Mobile Robotics (WMR) team. This robot was named ATLAS.},
	language = {en},
	author = {MacKinnon, Ollie},
	pages = {131}
}

@techreport{nahui_robocup_nodate,
	title = {{RoboCup} {Rescue} 2016 {Team} {Description} {Paper}},
	abstract = {This paper presents IXANAMIKI NAHUI, a prototype of rescue robot developed at the MCS Mobile Robotics Group to compete at RoboCup Rescue Robot League. IXNAMIKI NAHUI consists of a track wheel type structure. With double front a n d ba c k flippers, it is capable of moving, climbing and collapsing rough terrain. IXNAMIKI NAHUI also encompasses a 6-joint mechanical arm which can be deployed not only for surveillance from the top view but also for easier and faster access to the victims. Video cameras and a set of sensors are set up at the tip of the mechanical arm to aid the operator during rescue decision making. The mapping techniques included in this prototype take advantage of a 2D real-time laser scanning.},
	language = {en},
	author = {NAHUI, IXNAMIKI},
	pages = {7}
}

@article{pellenz_robocup_nodate,
	title = {{RoboCup} {Rescue} {Robot} {League}},
	abstract = {The RoboCup Rescue Robot League (RRL) aims to foster the development of rescue robots that can be used after disasters such as earthquakes. These robots help to discover victims in the collapsed structure without endanger the rescue personnel. The RRL has been held since 2000. The experience gained during these competitions has increased the level of maturity of the ﬁeld, which allowed to deploy robots after real disasters, e.g. at the Fukushima Daiichi nuclear disaster. This article provides an overview on the competition and its history. It also highlights the current state of the art, the current challenges and the way ahead.},
	language = {en},
	author = {Pellenz, Johannes and Jacoff, Adam and Kimura, Tetsuya and Mihankhah, Ehsan and Sheh, Raymond and Suthakorn, Jackrit},
	pages = {12}
}

@article{jacoff_counter-improvised_nodate,
	title = {Counter-{Improvised} {Explosive} {Device} {Training} {Using} {Standard} {Test} {Methods} for {Response} {Robots}},
	language = {en},
	author = {Jacoff, Adam and Virts, Ann and Saidi, Kam},
	pages = {11}
}

@article{messina_statement_nodate,
	title = {Statement of {Requirements} for {Urban} {Search} and {Rescue} {Robot} {Performance} {Standards}},
	language = {en},
	author = {Messina, Elena},
	pages = {91}
}

@techreport{warwick_robotics_technical_2005,
	title = {Technical {Report} : {Hardware}},
	author = {{\{Warwick Robotics\}}},
	year = {2005}
}

@book{noauthor_candictionary_2016,
	edition = {9},
	title = {{CANdictionary}},
	language = {English},
	publisher = {CAN-CIA},
	year = {2016}
}

@misc{noauthor_robocup_nodate,
	title = {{RoboCup} {Rescue} : {Team} {Description} {Paper} {Template}},
	url = {https://www.nist.gov/sites/defaus/documents/el/isd/RoboCupRescue_TDP.pdf},
	urldate = {2018-07-31}
}

@inproceedings{yue_reconfigurable_2012,
	title = {A {Reconfigurable} {Snake} {Robot} {Based} on {CAN}-{Bus}},
	isbn = {978-0-7695-4647-6 978-1-4673-0689-8},
	url = {http://ieeexplore.ieee.org/document/6187893/},
	doi = {10.1109/ICCSEE.2012.123},
	abstract = {This paper introduces the project "Snake Robot" we made for our National Innovation Fund. This snake robot has the ability to creep and wriggle. It adapts reconfiguration in the design of mechanism, control and supervising software, and brings in CAN-Bus which makes it possible that snake robot can extend infinitely in theory. The trial outcome proves that the snake robot can control easily, move flexibly and finish serpentine and wriggle locomotion very well.},
	language = {en},
	urldate = {2018-08-01},
	publisher = {IEEE},
	author = {Yue, Zhang and Xin, Li and Xianli, Zhou},
	month = mar,
	year = {2012},
	pages = {493--497}
}

@article{davies_reconfigurable_nodate,
	title = {A {Reconfigurable} {USAR} {Robot} {Designed} for {Traversing} {Complex} 3D {Terrain}},
	language = {en},
	author = {Davies, K and Ramirez-Serrano, A},
	pages = {2}
}

@article{paolo_towards_2017,
	title = {Towards continuous control of flippers for a multi-terrain robot using deep reinforcement learning},
	url = {http://arxiv.org/abs/1709.08430},
	abstract = {In this paper we focus on developing a control algorithm for multi-terrain tracked robots with ﬂippers using a reinforcement learning (RL) approach. The work is based on the deep deterministic policy gradient (DDPG) algorithm, proven to be very successful in simple simulation environments. The algorithm works in an end-to-end fashion in order to control the continuous position of the ﬂippers. This end-to-end approach makes it easy to apply the controller to a wide array of circumstances, but the huge ﬂexibility comes to the cost of an increased diﬃculty of solution. The complexity of the task is enlarged even more by the fact that real multi-terrain robots move in partially observable environments. Notwithstanding these complications, being able to smoothly control a multi-terrain robot can produce huge beneﬁts in impaired people daily lives or in search and rescue situations.},
	language = {en},
	urldate = {2018-08-02},
	journal = {arXiv:1709.08430 [cs]},
	author = {Paolo, Giuseppe and Tai, Lei and Liu, Ming},
	month = sep,
	year = {2017},
	note = {arXiv: 1709.08430},
	keywords = {Computer Science - Robotics, Computer Science - Artificial Intelligence, Computer Science - Machine Learning}
}

@article{parasuraman_new_2017,
	title = {A {New} {UGV} {Teleoperation} {Interface} for {Improved} {Awareness} of {Network} {Connectivity} and {Physical} {Surroundings}},
	url = {http://arxiv.org/abs/1710.06785},
	abstract = {A reliable wireless connection between the operator and the teleoperated Unmanned Ground Vehicle (UGV) is critical in many Urban Search and Rescue (USAR) missions. Unfortunately, as was seen in e.g. the Fukushima disaster, the networks available in areas where USAR missions take place are often severely limited in range and coverage. Therefore, during mission execution, the operator needs to keep track of not only the physical parts of the mission, such as navigating through an area or searching for victims, but also the variations in network connectivity across the environment.},
	language = {en},
	urldate = {2018-08-02},
	journal = {arXiv:1710.06785 [cs]},
	author = {Parasuraman, Ramviyas and Caccamo, Sergio and Båberg, Fredrik and Ögren, Petter and Neerincx, Mark},
	month = oct,
	year = {2017},
	note = {arXiv: 1710.06785},
	keywords = {Computer Science - Robotics, Computer Science - Human-Computer Interaction, Computer Science - Networking and Internet Architecture}
}

@article{gasteratos_tele-autonomous_2008,
	title = {Tele-{Autonomous} {Active} {Stereo}-{Vision} {Head}},
	volume = {2},
	issn = {1559-9612},
	url = {https://doi.org/10.1080/15599610802081753},
	doi = {10.1080/15599610802081753},
	abstract = {Supervised autonomy is defined as a framework to control robotic systems, which combines tele-operation in the high-level with autonomous functions in the low-level. The main advantage of such a scheme is that the human operator of the tele-operated device does not need to care about functions, which can be performed by a local controller and, thus, he remains undistracted during his activity. In this article, the autonomous functions that a robotized stereo head should bear to accomplish outdoors rescue tasks is discussed. Paradigm algorithms implementing these functions are presented and respective experimental results are apposed.},
	number = {2},
	urldate = {2018-08-07},
	journal = {International Journal of Optomechatronics},
	author = {Gasteratos, Antonios},
	month = jun,
	year = {2008},
	keywords = {Stereo head, Supervised autonomy, Tele-operation},
	pages = {144--161}
}

@article{burki_appearance-based_2018,
	title = {Appearance-{Based} {Landmark} {Selection} for {Efficient} {Long}-{Term} {Visual} {Localization}},
	url = {http://arxiv.org/abs/1808.02656},
	abstract = {We present an online landmark selection method for distributed long-term visual localization systems in bandwidth-constrained environments. Sharing a common map for online localization provides a fleet of au- tonomous vehicles with the possibility to maintain and access a consistent map source, and therefore reduce redundancy while increasing efficiency. However, connectivity over a mobile network imposes strict bandwidth constraints and thus the need to minimize the amount of exchanged data. The wide range of varying appearance conditions encountered during long-term visual localization offers the potential to reduce data usage by extracting only those visual cues which are relevant at the given time. Motivated by this, we propose an unsupervised method of adaptively selecting landmarks according to how likely these landmarks are to be observable under the prevailing appear- ance condition. The ranking function this selection is based upon exploits landmark co-observability statistics collected in past traversals through the mapped area. Evaluation is per- formed over different outdoor environments, large time-scales and varying appearance conditions, including the extreme tran- sition from day-time to night-time, demonstrating that with our appearance-dependent selection method, we can significantly reduce the amount of landmarks used for localization while maintaining or even improving the localization performance.},
	urldate = {2018-08-17},
	journal = {arXiv:1808.02656 [cs]},
	author = {Bürki, Mathias and Gilitschenski, Igor and Stumm, Elena and Siegwart, Roland and Nieto, Juan},
	month = aug,
	year = {2018},
	note = {arXiv: 1808.02656},
	keywords = {Computer Science - Robotics}
}

@article{burki_map_2018,
	title = {Map {Management} for {Efficient} {Long}-{Term} {Visual} {Localization} in {Outdoor} {Environments}},
	url = {http://arxiv.org/abs/1808.02658},
	abstract = {We present a complete map management process for a visual localization system designed for multi-vehicle long- term operations in resource constrained outdoor environments. Outdoor visual localization generates large amounts of data that need to be incorporated into a lifelong visual map in order to allow localization at all times and under all appearance conditions. Processing these large quantities of data is non- trivial, as it is subject to limited computational and storage capabilities both on the vehicle and on the mapping backend. We address this problem with a two-fold map update paradigm capable of, either, adding new visual cues to the map, or updating co-observation statistics. The former, in combination with offline map summarization techniques, allows enhancing the appearance coverage of the lifelong map while keeping the map size limited. On the other hand, the latter is able to significantly boost the appearance-based landmark selection for efficient online localization without incurring any additional computational or storage burden. Our evaluation in challenging outdoor conditions shows that our proposed map management process allows building and maintaining maps for precise visual localization over long time spans in a tractable and scalable fashion.},
	urldate = {2018-08-17},
	journal = {arXiv:1808.02658 [cs]},
	author = {Bürki, Mathias and Dymczyk, Marcin and Gilitschenski, Igor and Cadena, Cesar and Siegwart, Roland and Nieto, Juan},
	month = aug,
	year = {2018},
	note = {arXiv: 1808.02658},
	keywords = {Computer Science - Robotics}
}

@misc{latile_i2c_1995,
	title = {The {I}2C {Bus} and how to use it (including specifications)},
	language = {en},
	author = {LATILE, NMOICNR-VOO-},
	year = {1995}
}

@article{pecka_controlling_2017,
	title = {Controlling {Robot} {Morphology} from {Incomplete} {Measurements}},
	volume = {64},
	issn = {0278-0046, 1557-9948},
	url = {http://arxiv.org/abs/1612.02739},
	doi = {10.1109/TIE.2016.2580125},
	abstract = {Mobile robots with complex morphology are essential for traversing rough terrains in Urban Search \& Rescue missions (USAR). Since teleoperation of the complex morphology causes high cognitive load of the operator, the morphology is controlled autonomously. The autonomous control measures the robot state and surrounding terrain which is usually only partially observable, and thus the data are often incomplete. We marginalize the control over the missing measurements and evaluate an explicit safety condition. If the safety condition is violated, tactile terrain exploration by the body-mounted robotic arm gathers the missing data.},
	language = {en},
	number = {2},
	urldate = {2018-08-21},
	journal = {IEEE Transactions on Industrial Electronics},
	author = {Pecka, Martin and Zimmermann, Karel and Reinštein, Michal and Svoboda, Tomáš},
	month = feb,
	year = {2017},
	note = {arXiv: 1612.02739},
	keywords = {Computer Science - Robotics, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Systems and Control, I.2.9},
	pages = {1773--1782}
}

@article{parasuraman_few_2015,
	title = {Few common failure cases in mobile robots},
	url = {http://arxiv.org/abs/1508.03000},
	abstract = {A mobile robot deployed for remote inspection, surveying or rescue missions can fail due to various possibilities and can be hardware or software related. These failure scenarios necessitate manual recovery (self-rescue) of the robot from the environment. It would bring unforeseen challenges to recover the mobile robot if the environment where it was deployed had hazardous or harmful conditions (e.g. ionizing radiations). While it is not fully possible to predict all the failures in the robot, failures can be reduced by employing certain design/usage considerations. Few example failure cases based on real experiences are presented in this short article along with generic suggestions on overcoming the illustrated failure situations.},
	language = {en},
	urldate = {2018-08-21},
	journal = {arXiv:1508.03000 [cs]},
	author = {Parasuraman, Ramviyas},
	month = aug,
	year = {2015},
	note = {arXiv: 1508.03000},
	keywords = {Reliability, Robotics, Computer Science - Robotics}
}

@article{mielle_slam_2017,
	title = {{SLAM} auto-complete: completing a robot map using an emergency map},
	shorttitle = {{SLAM} auto-complete},
	url = {http://arxiv.org/abs/1702.05087},
	doi = {10.1109/SSRR.2017.8088137},
	abstract = {In search and rescue missions, time is an important factor; fast navigation and quickly acquiring situation awareness might be matters of life and death. Hence, the use of robots in such scenarios has been restricted by the time needed to explore and build a map. One way to speed up exploration and mapping is to reason about unknown parts of the environment using prior information. While previous research on using external priors for robot mapping mainly focused on accurate maps or aerial images, such data are not always possible to get, especially indoor. We focus on emergency maps as priors for robot mapping since they are easy to get and already extensively used by ﬁremen in rescue missions. However, those maps can be outdated, information might be missing, and the scales of rooms are typically not consistent.},
	language = {en},
	urldate = {2018-08-21},
	journal = {2017 IEEE International Symposium on Safety, Security and Rescue Robotics (SSRR)},
	author = {Mielle, Malcolm and Magnusson, Martin and Andreasson, Henrik and Lilienthal, Achim J.},
	month = oct,
	year = {2017},
	note = {arXiv: 1702.05087},
	keywords = {Computer Science - Robotics},
	pages = {35--40}
}

@article{vyroubalova_lidar_nodate,
	title = {{LIDAR} and stereo camera data fusion in mobile robot mapping},
	abstract = {LIDAR (2D) has been widely used for mapping and navigation in mobile robotics. However, its usage is limited to simple environments. This problem can be solved by adding more sensors and processing these data together. This paper explores a method how measurements from a stereo camera and LIDAR are fused to dynamical mapping. An occupancy grid map from LIDAR data is used as prerequisite and extended by a 2D grid map from stereo camera. This approach is based on the ground plane estimation in disparity map acquired from the stereo vision. For the ground plane detection, RANSAC and Least Squares methods are used. After obstacles determination, 2D occupancy map is generated. The output of this method is 2D map as a fusion of complementary maps from LIDAR and camera. Experimental results obtained from Willow Garage Stereo and Hokuyo UTM-30LX Laser are good enough to determine that this method is a beneﬁt, although my implementation is still a prototype. In this paper, we present the applied methods, analyze the results and discuss the modiﬁcations and possible extensions to get better results.},
	language = {en},
	author = {Vyroubalová, Jana},
	pages = {8}
}

@article{labbe_simultaneous_nodate,
	title = {Simultaneous {Localization} and {Mapping} ({SLAM}) with {RTAB}-{Map}},
	language = {en},
	author = {Labbé, Mathieu},
	pages = {31}
}

@article{mendoza_robot_nodate,
	title = {Robot {SLAM} and {Navigation} with {Multi}-{Camera} {Computer} {Vision}},
	language = {en},
	author = {Mendoza, Gerardo Carrera},
	pages = {180}
}

@article{priyandoko_mapping_2017,
	title = {Mapping of unknown industrial plant using {ROS}-based navigation mobile robot},
	volume = {257},
	issn = {1757-8981, 1757-899X},
	url = {http://stacks.iop.org/1757-899X/257/i=1/a=012088?key=crossref.e98f8ed74fd83911607cf0c1d59a35bf},
	doi = {10.1088/1757-899X/257/1/012088},
	abstract = {This research examines how humans work with teleoperated unmanned mobile robot inspection in industrial plant area resulting 2D/3D map for further critical evaluation. This experiment focuses on two parts, the way human-robot doing remote interactions using robust method and the way robot perceives the environment surround as a 2D/3D perspective map. ROS (robot operating system) as a tool was utilized in the development and implementation during the research which comes up with robust data communication method in the form of messages and topics. RGBD SLAM performs the visual mapping function to construct 2D/3D map using Kinect sensor. The results showed that the mobile robot-based teleoperated system are successful to extend human perspective in term of remote surveillance in large area of industrial plant. It was concluded that the proposed work is robust solution for large mapping within an unknown construction building.},
	language = {en},
	urldate = {2018-08-21},
	journal = {IOP Conference Series: Materials Science and Engineering},
	author = {Priyandoko, G. and Ming, T. Y. and Achmad, M. S. H.},
	month = oct,
	year = {2017},
	pages = {012088}
}

@inproceedings{caruso_large-scale_2015,
	address = {Hamburg, Germany},
	title = {Large-scale direct {SLAM} for omnidirectional cameras},
	isbn = {978-1-4799-9994-1},
	url = {http://ieeexplore.ieee.org/document/7353366/},
	doi = {10.1109/IROS.2015.7353366},
	abstract = {We propose a real-time, direct monocular SLAM method for omnidirectional or wide ﬁeld-of-view ﬁsheye cameras. Both tracking (direct image alignment) and mapping (pixel-wise distance ﬁltering) are directly formulated for the uniﬁed omnidirectional model, which can model central imaging devices with a ﬁeld of view well above 150◦. This is in stark contrast to existing direct mono-SLAM approaches like DTAM or LSD-SLAM, which operate on rectiﬁed images, limiting the ﬁeld of view to well below 180◦. Not only does this allow to observe – and reconstruct – a larger portion of the surrounding environment, but it also makes the system more robust to degenerate (rotation-only) movement. The two main contribution are (1) the formulation of direct image alignment for the uniﬁed omnidirectional model, and (2) a fast yet accurate approach to incremental stereo directly on distorted images. We evaluated our framework on real-world sequences taken with a 185◦ ﬁsh-eye lens, and compare it to a rectiﬁed and a piecewise rectiﬁed approach.},
	language = {en},
	urldate = {2018-08-21},
	booktitle = {2015 {IEEE}/{RSJ} {International} {Conference} on {Intelligent} {Robots} and {Systems} ({IROS})},
	publisher = {IEEE},
	author = {Caruso, David and Engel, Jakob and Cremers, Daniel},
	month = sep,
	year = {2015},
	pages = {141--148}
}

@article{barbara_co2_nodate,
	title = {{CO}2 {Sensor} {Sniffs} {Out} {Human} {Smugglers}},
	language = {en},
	author = {Barbara, Santa},
	pages = {2}
}

@inproceedings{kadous_effective_2006,
	address = {Salt Lake City, Utah, USA},
	title = {Effective user interface design for rescue robotics},
	isbn = {978-1-59593-294-5},
	url = {http://portal.acm.org/citation.cfm?doid=1121241.1121285},
	doi = {10.1145/1121241.1121285},
	abstract = {Until robots are able to autonomously navigate, carry out a mission and report back to base, eﬀective human-robot interfaces will be an integral part of any practical mobile robot system. This is especially the case for robot-assisted Urban Search and Rescue (USAR). Unfamiliar and unstructured environments, unreliable communications and many sensors combine to make the job of a human operator, and hence the interface designer challenging.},
	language = {en},
	urldate = {2018-08-28},
	booktitle = {Proceeding of the 1st {ACM} {SIGCHI}/{SIGART} conference on {Human}-robot interaction  - {HRI} '06},
	publisher = {ACM Press},
	author = {Kadous, M. Waleed and Sheh, Raymond Ka-Man and Sammut, Claude},
	year = {2006},
	pages = {250}
}

@article{ohi_design_2018,
	title = {Design of an {Autonomous} {Precision} {Pollination} {Robot}},
	url = {http://arxiv.org/abs/1808.10010},
	abstract = {Precision robotic pollination systems can not only fill the gap of declining natural pollinators, but can also surpass them in efficiency and uniformity, helping to feed the fast-growing human population on Earth. This paper presents the design and ongoing development of an autonomous robot named "BrambleBee", which aims at pollinating bramble plants in a greenhouse environment. Partially inspired by the ecology and behavior of bees, BrambleBee employs state-of-the-art localization and mapping, visual perception, path planning, motion control, and manipulation techniques to create an efficient and robust autonomous pollination system.},
	urldate = {2018-09-03},
	journal = {arXiv:1808.10010 [cs]},
	author = {Ohi, Nicholas and Lassak, Kyle and Watson, Ryan and Strader, Jared and Du, Yixin and Yang, Chizhao and Hedrick, Gabrielle and Nguyen, Jennifer and Harper, Scott and Reynolds, Dylan and Kilic, Cagri and Hikes, Jacob and Mills, Sarah and Castle, Conner and Buzzo, Benjamin and Waterland, Nicole and Gross, Jason and Park, Yong-Lak and Li, Xin and Gu, Yu},
	month = aug,
	year = {2018},
	note = {arXiv: 1808.10010},
	keywords = {Computer Science - Robotics}
}

@article{vilches_robot_gym:_2018,
	title = {Robot\_gym: accelerated robot training through simulation in the cloud with {ROS} and {Gazebo}},
	shorttitle = {Robot\_gym},
	url = {http://arxiv.org/abs/1808.10369},
	abstract = {Rather than programming, training allows robots to achieve behaviors that generalize better and are capable to respond to real-world needs. However, such training requires a big amount of experimentation which is not always feasible for a physical robot. In this work, we present robot\_gym, a framework to accelerate robot training through simulation in the cloud that makes use of roboticists' tools, simplifying the development and deployment processes on real robots. We unveil that, for simple tasks, simple 3DoF robots require more than 140 attempts to learn. For more complex, 6DoF robots, the number of attempts increases to more than 900 for the same task. We demonstrate that our framework, for simple tasks, accelerates the robot training time by more than 33\% while maintaining similar levels of accuracy and repeatability.},
	urldate = {2018-09-03},
	journal = {arXiv:1808.10369 [cs]},
	author = {Vilches, Víctor Mayoral and Cordero, Alejandro Hernández and Calvo, Asier Bilbao and Ugarte, Irati Zamalloa and Kojcev, Risto},
	month = aug,
	year = {2018},
	note = {arXiv: 1808.10369},
	keywords = {Computer Science - Robotics, Computer Science - Artificial Intelligence, Computer Science - Machine Learning}
}

@inproceedings{sheh_human-system_2015,
	address = {West Lafayette, IN, USA},
	title = {Human-system interaction for bomb squad applications: {Preliminary} experiments with low cost cameras in real world deployment},
	isbn = {978-1-5090-1959-5},
	shorttitle = {Human-system interaction for bomb squad applications},
	url = {http://ieeexplore.ieee.org/document/7442999/},
	doi = {10.1109/SSRR.2015.7442999},
	abstract = {A sufﬁcient level of situational awareness is crucial in the operation of remote, teleoperated robots to fulﬁl a mission. While much work has been done in user interfaces, camera systems and so-on to improve situational awareness, it is an unfortunate fact that few of these developments have ﬁltered down into operational use. In this paper, we describe our preliminary work on improving situational awareness provided to the operator of a tEODor Explosive Ordnance Disposal Robot. We focus on the effect of adding low cost wide angle cameras to an existing, deployed robotic platform and the result of experiments as to effective placement of the cameras within the existing robot system. Unique to our work is the fact that these improvements have been used operationally and found to improve mission performance.},
	language = {en},
	urldate = {2018-09-10},
	booktitle = {2015 {IEEE} {International} {Symposium} on {Safety}, {Security}, and {Rescue} {Robotics} ({SSRR})},
	publisher = {IEEE},
	author = {Sheh, Raymond and Mees, David},
	month = oct,
	year = {2015},
	pages = {1--6}
}

@incollection{yoshida_advancing_2014,
	address = {Berlin, Heidelberg},
	title = {Advancing the {State} of {Urban} {Search} and {Rescue} {Robotics} {Through} the {RoboCupRescue} {Robot} {League} {Competition}},
	volume = {92},
	isbn = {978-3-642-40685-0 978-3-642-40686-7},
	url = {http://link.springer.com/10.1007/978-3-642-40686-7_9},
	language = {en},
	urldate = {2018-09-10},
	booktitle = {Field and {Service} {Robotics}},
	publisher = {Springer Berlin Heidelberg},
	author = {Sheh, Raymond and Jacoff, Adam and Virts, Ann-Marie and Kimura, Tetsuya and Pellenz, Johannes and Schwertfeger, Sören and Suthakorn, Jackrit},
	editor = {Yoshida, Kazuya and Tadokoro, Satoshi},
	year = {2014},
	doi = {10.1007/978-3-642-40686-7_9},
	pages = {127--142}
}

@inproceedings{jacoff_using_2012,
	address = {College Park, Maryland},
	title = {Using competitions to advance the development of standard test methods for response robots},
	isbn = {978-1-4503-1126-7},
	url = {http://dl.acm.org/citation.cfm?doid=2393091.2393126},
	doi = {10.1145/2393091.2393126},
	abstract = {Competitions are an effective aid to the development and dissemination of standard test methods, especially in rapidly developing, fields with a wide variety of requirements and capabilities such as Urban Search and Rescue robotics. By exposing the development process to highly developmental systems that push the boundaries of current capabilities, it is possible to gain an insight into how the test methods will respond to the robots of the future. The competition setting also allows for the rapid iterative refinement of the test methods and apparatuses in response to new developments. For the research community, introducing the concepts behind the test methods at the research and development stage can also help to guide their work towards the operationally relevant requirements embodied by the test methods and apparatuses. This also aids in the dissemination of the test methods themselves as teams fabricate them in their own laboratories and re-use them in work outside the competition. In this paper, we discuss how international competitions, and in particular the RoboCupRescue Robot League competition, have played a crucial role in the development of standard test metrics for response robots as part of the ASTM International Committee of Homeland Security Applications; Operational Equipment; Robots (E54.08.01). We will also discuss how the competition has helped to drive a vibrant robot developer community towards solutions that are relevant to first responders.},
	language = {en},
	urldate = {2018-09-10},
	booktitle = {Proceedings of the {Workshop} on {Performance} {Metrics} for {Intelligent} {Systems} - {PerMIS} '12},
	publisher = {ACM Press},
	author = {Jacoff, Adam and Sheh, Raymond and Virts, Ann-Marie and Kimura, Tetsuya and Pellenz, Johannes and Schwertfeger, Sören and Suthakorn, Jackrit},
	year = {2012},
	pages = {182}
}

@techreport{noauthor_c++_nodate,
	title = {C++ {International} {Standard}}
}

@article{redmon_you_2015,
	title = {You {Only} {Look} {Once}: {Unified}, {Real}-{Time} {Object} {Detection}},
	shorttitle = {You {Only} {Look} {Once}},
	url = {http://arxiv.org/abs/1506.02640},
	abstract = {We present YOLO, a new approach to object detection. Prior work on object detection repurposes classiﬁers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance.},
	language = {en},
	urldate = {2018-09-14},
	journal = {arXiv:1506.02640 [cs]},
	author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
	month = jun,
	year = {2015},
	note = {arXiv: 1506.02640},
	keywords = {Computer Science - Computer Vision and Pattern Recognition}
}

@article{gupta_open_2018,
	title = {Open {Problems} in {Robotic} {Anomaly} {Detection}},
	url = {http://arxiv.org/abs/1809.03565},
	abstract = {Failures in robotics can have disastrous consequences that worsen rapidly over time. This, the ability to rely on robotic systems, depends on our ability to monitor them and intercede when necessary, manually or autonomously. Prior work in this area surveys intrusion detection and security challenges in robotics, but a discussion of the more general anomaly detection problems is lacking. As such, we provide a brief insight-focused discussion and frameworks of thought on some compelling open problems with anomaly detection in robotic systems. Namely, we discuss non-malicious faults, invalid data, intentional anomalous behavior, hierarchical anomaly detection, distribution of computation, and anomaly correction on the fly. We demonstrate the need for additional work in these areas by providing a case study which examines the limitations of implementing a basic anomaly detection (AD) system in the Robot Operating System (ROS) 2 middleware. Showing that if even supporting a basic system is a significant hurdle, the path to more complex and advanced AD systems is even more problematic. We discuss these ROS 2 platform limitations to support solutions in robotic anomaly detection and provide recommendations to address the issues discovered.},
	urldate = {2018-09-14},
	journal = {arXiv:1809.03565 [cs]},
	author = {Gupta, Ritwik and Kurtz, Zachary T. and Scherer, Sebastian and Smereka, Jonathon M.},
	month = sep,
	year = {2018},
	note = {arXiv: 1809.03565},
	keywords = {Computer Science - Robotics}
}

@article{paillat_conception_nodate,
	title = {Conception et contrôle de robots à géométrie variable: applications au franchissement d'obstacles autonome},
	language = {fr},
	author = {Paillat, Jean-Luc},
	pages = {154}
}

@inproceedings{zou_mechanical_2016,
	title = {Mechanical design of a self-adaptive transformable tracked robot for cable tunnel inspection},
	doi = {10.1109/ICMA.2016.7558715},
	abstract = {According to the environment and requirements of cable tunnel inspection, an inspecting mobile robot with self-adaptive transformable tracked mechanism and modular design method is proposed. The mechanical system of the robot consists of one chassis module, two self-adaptive transformable track modules, and one wheeled tail module. The chassis module is used for carrying the control system and connecting other modules. The self-adaptive transformable track module is used for moving and clearing obstacles. The tail wheel module is used for preventing the tip-over during clearing obstacles. Based on analyzing the functions of each module, the mechanical design work is completed, and the robot prototype is built. Finally, the experiment is carried out to verify the adaptability of the robot for the cable tunnel environment.},
	booktitle = {2016 {IEEE} {International} {Conference} on {Mechatronics} and {Automation}},
	author = {Zou, M. and Bai, H. and Wang, Y. and Yu, S.},
	month = aug,
	year = {2016},
	keywords = {mobile robots, Belts, Cable tunnel, cable tunnel inspection, cables (mechanical), chassis module, clearing obstacles, Gears, inspecting mobile robot, inspection, Legged locomotion, Mechanical cables, mechanical design, modular, modular design method, moving obstacles, prototypes, robot mechanical system, self-adaptive, self-adaptive transformable tracked robot, tip-over prevention, transformable tracked mechanism, tunnels, wheeled tail module, wheels, Wheels},
	pages = {1096--1100}
}

@article{lim_reconfiguration_2012,
	title = {Reconfiguration {Planning} for a {Robotic} {Vehicle} with {Actively} {Articulated} {Suspension} in {Obstacle} {Terrain} during {Straight} {Motion}},
	volume = {26},
	issn = {0169-1864},
	url = {https://doi.org/10.1080/01691864.2012.690191},
	doi = {10.1080/01691864.2012.690191},
	abstract = {In this paper, an actively articulated suspension (AAS) reconfiguration method is proposed for a robotic vehicle with AAS to negotiate an obstacle during straight motion. Proposed method includes AAS locomotion for the locomotion with the AAS and a calculation method that is independent to the terrain model for posture control using the AAS reconfiguration. Using simulations, it was verified that the proposed method can reconfigure the AAS for a robotic vehicle to have the desired position and posture to negotiate an obstacle. The errors of height and orientation can be reduced while wheel driving on rough terrain. Also, the robot can maintain a minimum static stability angle over 0.6 rad. When observing the obstacle negotiation procedure using the AAS reconfiguration including the proposed locomotion, it was found that the robot can conduct a high-level command successfully using the proposed method. The robot can negotiate an obstacle with a height of 71\% of its usable length and can maintain the minimum static stability over 0.3 rad. Also, the robot can manage terrain uncertainty using the proposed AAS reconfiguration method.},
	number = {13},
	urldate = {2018-09-18},
	journal = {Advanced Robotics},
	author = {Lim, Kyeong Bin and Yoon, Yong-San},
	month = aug,
	year = {2012},
	keywords = {articulated suspension, locomotion pattern, obstacle negotiation, robotic vehicle, suspension reconfiguration},
	pages = {1471--1494}
}

@article{paillat_original_2010,
	title = {Original {Design} of an {Unmanned} {Ground} {Vehicle} for {Exploration} in {Rough} {Terrain}},
	volume = {24},
	issn = {01691864},
	url = {http://search.ebscohost.com/login.aspx?direct=true&db=egs&AN=48028446&site=ehost-live},
	doi = {10.1163/016918609X12586221919482},
	abstract = {This paper introduces an originally designed tracked robot. This robot belongs to the variable geometry single-tracked vehicle (VGSTV) category. Two active joints are used to control the shape of the vehicle and the tension of the tracks. Thus, it becomes possible to adapt the shape of the robot and the ground/robot contact points to the obstacle by controlling the joints. This paper presents some unmanned ground vehicle architectures followed by an analysis of the prototype performance (in comparison with other VGSTVs). A description of its dynamic model is also presented in order to introduce the computation of two balance criteria: center of gravity and zero moment point. Finally, the relevance of these criteria is compared by discussing experimental results in the case of staircase clearing.},
	number = {1/2},
	urldate = {2018-09-18},
	journal = {Advanced Robotics},
	author = {Paillat, Jean-Luc and Lucidarme, Philippe and Hardouin, Laurent},
	month = jan,
	year = {2010},
	keywords = {ROBOTS, balance, CLEARANCE CAPABILITY, DYNAMO (Computer program language), ELECTRIC controllers, REMOTE control, REMOTELY piloted vehicles, tele-operation, UNMANNED GROUND VEHICLE, VARIABLE GEOMETRY SINGLE-TRACKED VEHICLE},
	pages = {255--276}
}

@techreport{koikeroinen_milcan_2006,
	address = {Kariskoga, Sweden},
	type = {Standard},
	title = {{MilCAN} {B} {Specification}},
	language = {en},
	number = {MWG-MILB-001},
	institution = {BAE Systems Bofors AB},
	author = {Koikeroinen, L},
	month = sep,
	year = {2006},
	pages = {79}
}

@misc{harris_researcher_2015,
	title = {Researcher {Hacks} {Self}-driving {Car} {Sensors}},
	url = {https://spectrum.ieee.org/cars-that-think/transportation/self-driving/researcher-hacks-selfdriving-car-sensors},
	abstract = {\$60 lidar spoofing device generates fake cars, pedestrians and walls},
	language = {en},
	urldate = {2018-09-19},
	journal = {IEEE Spectrum: Technology, Engineering, and Science News},
	author = {Harris, Mark},
	month = sep,
	year = {2015}
}

@article{van_nguyen_trackerbots:_2017,
	title = {{TrackerBots}: {Autonomous} {UAV} for {Real}-{Time} {Localization} and {Tracking} of {Multiple} {Radio}-{Tagged} {Animals}},
	shorttitle = {{TrackerBots}},
	url = {http://arxiv.org/abs/1712.01491},
	abstract = {Autonomous aerial robots provide new possibilities to study the habitats and behaviors of endangered species through the efficient gathering of location information at temporal and spatial granularities not possible with traditional manual survey methods. We present a novel autonomous aerial vehicle system-TrackerBots-to track and localize multiple radio-tagged animals. The simplicity of measuring the received signal strength indicator (RSSI) values of very high frequency (VHF) radio-collars commonly used in the field is exploited to realize a low cost and lightweight tracking platform suitable for integration with unmanned aerial vehicles (UAVs). Due to uncertainty and the nonlinearity of the system based on RSSI measurements, our tracking and planning approaches integrate a particle filter for tracking and localizing; a partially observable Markov decision process (POMDP) for dynamic path planning. This approach allows autonomous navigation of a UAV in a direction of maximum information gain to locate multiple mobile animals and reduce exploration time; and, consequently, conserve onboard battery power. We also employ the concept of a search termination criteria to maximize the number of located animals within power constraints of the aerial system. We validated our real-time and online approach through both extensive simulations and field experiments with two mobile VHF radio-tags.},
	urldate = {2018-09-22},
	journal = {arXiv:1712.01491 [cs]},
	author = {Van Nguyen, Hoa and Chesser, Michael and Koh, Lian Pin and Rezatofighi, S. Hamid and Ranasinghe, Damith C.},
	month = dec,
	year = {2017},
	note = {arXiv: 1712.01491},
	keywords = {Computer Science - Robotics, Computer Science - Systems and Control}
}

@article{noauthor_um10204_2014,
	title = {{UM}10204 {I}2C-bus specification and user manual},
	volume = {2014},
	language = {en},
	year = {2014},
	pages = {64}
}

@misc{bugeja_how_2018,
	title = {How to {Print} an {Electric} {Motor}},
	url = {https://spectrum.ieee.org/geek-life/hands-on/how-to-print-an-electric-motor},
	abstract = {An axial flux motor uses printed-circuit-board traces for electromagnetic coils},
	language = {en},
	urldate = {2018-10-01},
	journal = {IEEE Spectrum: Technology, Engineering, and Science News},
	author = {Bugeja, Carl},
	month = aug,
	year = {2018}
}

@book{art_kay_analog_nodate,
	title = {Analog {Engineer}’s {Circuit} {Cookbook}: {ADCs}},
	language = {en},
	publisher = {Texas Instruments},
	editor = {{Art Kay} and {Luis Chioye} and {Dale Li}}
}

@book{trump_signal_nodate,
	title = {The {Signal} - {A} compendium of blog posts on op amp design topics},
	language = {en},
	publisher = {Texas Instruments},
	author = {Trump, Bruce}
}

@article{pinheiro_failure_nodate,
	title = {Failure {Trends} in a {Large} {Disk} {Drive} {Population}},
	abstract = {It is estimated that over 90\% of all new information produced in the world is being stored on magnetic media, most of it on hard disk drives. Despite their importance, there is relatively little published work on the failure patterns of disk drives, and the key factors that affect their lifetime. Most available data are either based on extrapolation from accelerated aging experiments or from relatively modest sized ﬁeld studies. Moreover, larger population studies rarely have the infrastructure in place to collect health signals from components in operation, which is critical information for detailed failure analysis.},
	language = {en},
	author = {Pinheiro, Eduardo and Weber, Wolf-Dietrich and Barroso, Luiz Andre},
	pages = {13}
}

@book{art_kay_analog_nodate-1,
	title = {Analog {Engineer}'s {Pocket} {Reference}},
	language = {English},
	publisher = {Texas Instruments},
	editor = {{Art Kay} and {Tim Green}}
}

@article{zheng_ros_nodate,
	title = {{ROS} {Navigation} {Tuning} {Guide}},
	language = {en},
	author = {Zheng, Kaiyu},
	pages = {19}
}

@book{noauthor_search_2017,
	title = {Search and {Rescue} {Robotics} - {From} {Theory} to {Practice}},
	isbn = {978-953-51-3376-6},
	url = {https://www.intechopen.com/books/search-and-rescue-robotics-from-theory-to-practice},
	abstract = {In the event of large crises (earthquakes, typhoons, floods, ...), a primordial task of the fire and rescue services is the search for human survivors on the incident site. This is a complex and dangerous task, which - too often - leads to loss of lives among the human crisis managers themselves. This book explains how unmanned search can be added to the  toolkit of the search and rescue workers, offering a valuable tool to save human lives and to speed up the search and rescue process. 
The introduction of robotic tools in the world of search and rescue is not straightforward, due to the fact that the search and rescue context is extremely technology-unfriendly, meaning that very robust solutions, which can be deployed extremely quickly, are required. Multiple research projects across the world are tackling this problem and in this book, a special focus is placed on showcasing the results of the European Union ICARUS project on this subject.
The ICARUS project proposes to equip first responders with a comprehensive and integrated set of unmanned search and rescue tools, to increase the situational awareness of human crisis managers, so that more work can be done in a shorter amount of time. The ICARUS tools consist of assistive unmanned air, ground, and sea vehicles, equipped with victim-detection sensors. The unmanned vehicles collaborate as a coordinated team, communicating via ad hoc cognitive radio networking. To ensure optimal human-robot collaboration, these tools are seamlessly integrated into the command and control equipment of the human crisis managers and a set of training and support tools is provided to them in order to learn to use the ICARUS system.
{\textless}br{\textgreater}
{\textless}img style="float: left; margin-right: 10px; margin-top: 7px; width: 100\%;" src="//cdn.intechopen.com/public/images/icarus.png" alt="Icarus" height="150"{\textgreater}
{\textless}br{\textgreater}
{\textless}span style="font-style: italic; font-size: 85\%;"{\textgreater}
The research leading to these results has received funding from the European Community's Seventh Framework Programme (FP7/2007-2013) under grant agreement number 285417. The publishing of this book was funded by the EC FP7 Post-Grant Open Access Pilot programme. {\textless}/span{\textgreater}},
	language = {en},
	urldate = {2018-11-01},
	month = aug,
	year = {2017},
	doi = {10.5772/intechopen.68449}
}

@article{hastie_development_nodate,
	title = {Development of a new arm for the foster-miller talon robot},
	abstract = {Explosive Ordnance Disposal (EOD) robots save the lives of soldiers and civilians every day. The TALON robot by Foster-Miller is the choice of many military EOD teams and civilian bomb squads. The TALON robot’s manipulator arm is extremely capable, but does have its limitations. The addition of a shoulder rotational degree of freedom while maintaining the ruggedness, ease of maintenance, and mounting points to the platform would greatly improve the soldier’s ability to disable explosives. This paper examines similar EOD robot arms, especially the TALON’s closest competitor, the Packbot EOD. It also discusses alternative power transmission methods as well as novel manipulator designs. Our design leaves two motors in the base of the robot and transmits power to the shoulder pitch and shoulder rotation using a setup similar to a differential. The elbow motor will be mounted above this and transmit power within the upper arm. The paper also discusses challenges that occurred during the design process and a detailed analysis of all major components within the arm. Solid modeling of the arm, an in depth discussion of how the arm works, and the prototype build process are also included in the report. The arm was ultimately assembled at Northeastern University. The design was integrated with the TALON platform and was tested for dexterity. The test demonstrated the successful rotation and pitch of the new shoulder joint as well as the new elbow drive.},
	language = {en},
	author = {Hastie, Jon T},
	pages = {150}
}

@article{mehaboobe_making_nodate,
	title = {Making and breaking security in embedded devices},
	language = {en},
	author = {Mehaboobe, Yashin},
	pages = {40}
}

@article{behzadan_trolleymod_2018,
	title = {{TrolleyMod} v1.0: {An} {Open}-{Source} {Simulation} and {Data}-{Collection} {Platform} for {Ethical} {Decision} {Making} in {Autonomous} {Vehicles}},
	shorttitle = {{TrolleyMod} v1.0},
	url = {http://arxiv.org/abs/1811.05594},
	abstract = {This paper presents TrolleyMod v1.0, an open-source platform based on the CARLA simulator for the collection of ethical decision-making data for autonomous vehicles. This platform is designed to facilitate experiments aiming to observe and record human decisions and actions in high-fidelity simulations of ethical dilemmas that occur in the context of driving. Targeting experiments in the class of trolley problems, TrolleyMod provides a seamless approach to creating new experimental settings and environments with the realistic physics-engine and the high-quality graphical capabilities of CARLA and the Unreal Engine. Also, TrolleyMod provides a straightforward interface between the CARLA environment and Python to enable the implementation of custom controllers, such as deep reinforcement learning agents. The results of such experiments can be used for sociological analyses, as well as the training and tuning of value-aligned autonomous vehicles based on social values that are inferred from observations.},
	urldate = {2018-11-15},
	journal = {arXiv:1811.05594 [cs]},
	author = {Behzadan, Vahid and Minton, James and Munir, Arslan},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.05594},
	keywords = {Computer Science - Robotics, Computer Science - Artificial Intelligence, Computer Science - Computers and Society}
}

@article{zhao_reactive_2018,
	title = {Reactive {Task} and {Motion} {Planning} for {Robust} {Whole}-{Body} {Dynamic} {Locomotion} in {Constrained} {Environments}},
	url = {http://arxiv.org/abs/1811.04333},
	abstract = {Contact-based decision and planning methods are becoming increasingly important to endow higher levels of autonomy for legged robots. Formal synthesis methods derived from symbolic systems have great potential for reasoning about high-level locomotion decisions and achieving complex maneuvering behaviors with correctness guarantees. This study takes a first step toward formally devising an architecture composed of task planning and control of whole-body dynamic locomotion behaviors in constrained and dynamically changing environments. At the high level, we formulate a two-player temporal logic game between the multi-limb locomotion planner and its dynamic environment to synthesize a winning strategy that delivers symbolic locomotion actions. These locomotion actions satisfy the desired high-level task specifications expressed in a fragment of temporal logic. Those actions are sent to a robust finite transition system that synthesizes a locomotion controller that fulfills state reachability constraints. This controller is further executed via a low-level motion planner that generates feasible locomotion trajectories. We construct a set of dynamic locomotion models for legged robots to serve as a template library for handling diverse environmental events. We devise a replanning strategy that takes into consideration sudden environmental changes or large state disturbances to increase the robustness of the resulting locomotion behaviors. We formally prove the correctness of the layered locomotion framework guaranteeing a robust implementation by the motion planning layer. Simulations of reactive locomotion behaviors in diverse environments indicate that our framework has the potential to serve as a theoretical foundation for intelligent locomotion behaviors.},
	urldate = {2018-11-15},
	journal = {arXiv:1811.04333 [cs]},
	author = {Zhao, Ye and Li, Yinan and Sentis, Luis and Topcu, Ufuk and Liu, Jun},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.04333},
	keywords = {Computer Science - Robotics, Computer Science - Systems and Control, Computer Science - Formal Languages and Automata Theory}
}

@article{tiwari_estimating_2018,
	title = {Estimating {Achievable} {Range} of {Ground} {Robots} {Operating} on {Single} {Battery} {Discharge} for {Operational} {Efficacy} {Amelioration}},
	url = {http://arxiv.org/abs/1811.03159},
	abstract = {Mobile robots are increasingly being used to assist with active pursuit and law enforcement. One major limitation for such missions is the resource (battery) allocated to the robot. Factors like nature and agility of evader, terrain over which pursuit is being carried out, plausible traversal velocity and the amount of necessary data to be collected all influence how long the robot can last in the field and how far it can travel. In this paper, we develop an analytical model that analyzes the energy utilization for a variety of components mounted on a robot to estimate the maximum operational range achievable by the robot operating on a single battery discharge. We categorize the major consumers of energy as: 1.) ancillary robotic functions such as computation, communication, sensing etc., and 2.) maneuvering which involves propulsion, steering etc. Both these consumers draw power from the common power source but the achievable range is largely affected by the proportion of power available for maneuvering. For this case study, we performed experiments with real robots on planar and graded surfaces and evaluated the estimation error for each case.},
	urldate = {2018-11-15},
	journal = {arXiv:1811.03159 [cs]},
	author = {Tiwari, Kshitij and Xiao, Xuesu and Chong, Nak Young},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.03159},
	keywords = {Computer Science - Robotics}
}

@patent{mergener_universal_2017,
	title = {Universal protocol for power tools},
	url = {https://patents.google.com/patent/US20170300406A1/en?assignee=Milwaukee+Electric+Tool+Corp&sort=new&page=12},
	nationality = {US},
	language = {en},
	assignee = {Milwaukee Electric Tool Corp},
	number = {US20170300406A1},
	urldate = {2018-11-28},
	author = {Mergener, Matthew J.},
	month = oct,
	year = {2017},
	keywords = {communication, memory, power tool, request, tool, Milwaukee Tools}
}

@patent{meyer_method_2018,
	title = {Method and system for charging multi-cell lithium-based battery packs},
	url = {https://patents.google.com/patent/US20180309304A1/en?assignee=Milwaukee+Electric+Tool+Corp&sort=new},
	nationality = {US},
	language = {en},
	assignee = {Milwaukee Electric Tool Corp},
	number = {US20180309304A1},
	urldate = {2018-11-28},
	author = {Meyer, Gary D. and Rosenbecker, Jay J. and Glasgow, Kevin L. and Johnson, Todd W. and Scheucher, Karl F.},
	month = oct,
	year = {2018},
	keywords = {battery, charge, charging, controller, step, Milwaukee Tools}
}

@book{simmonds_mastering_2017,
	address = {Birmingham},
	title = {Mastering {Embedded} {Linux} {Programming} - {Second} {Edition}.},
	isbn = {978-1-78728-885-0},
	url = {http://public.eblib.com/choice/publicfullrecord.aspx?p=4898669},
	abstract = {Master the techniques needed to build great, efficient embedded devices on LinuxAbout This Book* Discover how to build and configure reliable embedded Linux devices* This book has been updated to include Linux 4.9 and Yocto Project 2.2 (Morty)* This comprehensive guide covers the remote update of devices in the field and power managementWho This Book Is ForIf you are an engineer who wishes to understand and use Linux in embedded devices, this book is for you. It is also for Linux developers and system programmers who are familiar with embedded systems and want to learn and program the best in class devices. It is appropriate for students studying embedded techniques, for developers implementing embedded Linux devices, and engineers supporting existing Linux devices. What You Will Learn* Evaluate the Board Support Packages offered by most manufacturers of a system on chip or embedded module* Use Buildroot and the Yocto Project to create embedded Linux systems quickly and efficiently* Update IoT devices in the field without compromising security* Reduce the power budget of devices to make batteries last longer* Interact with the hardware without having to write kernel device drivers* Debug devices remotely using GDB, and see how to measure the performance of the systems using powerful tools such as perk, ftrace, and valgrind* Find out how to configure Linux as a real-time operating systemIn DetailEmbedded Linux runs many of the devices we use every day, from smart TVs to WiFi routers, test equipment to industrial controllers - all of them have Linux at their heart. Linux is a core technology in the implementation of the inter-connected world of the Internet of Things. The comprehensive guide shows you the technologies and techniques required to build Linux into embedded systems. You will begin by learning about the fundamental elements that underpin all embedded Linux projects: the toolchain, the bootloader, the kernel, and the rosystem. You'll see how to create each of these elements from scratch, and how to automate the process using Buildroot and the Yocto Project. Moving on, you'll find out how to implement an effective storage strategy for flash memory chips, and how to install updates to the device remotely once it is deployed. You'll also get to know the key aspects of writing code for embedded Linux, such as how to access hardware from applications, the implications of writing multi-threaded code, and techniques to manage memory in an efficient way. The final chapters show you how to debug your code, both in applications and in the Linux kernel, and how to  the system so that you can look out for performance bottlenecks. By the end of the book, you will have a complete overview of the steps required to create a successful embedded Linux system. Style and approachThis book is an easy-to-follow and pragmatic guide with in-depth analysis of the implementation of embedded devices. It follows the life cycle of a project from inception through to completion, at each stage giving both the theory that underlies the topic and practical step-by-step walkthroughs of an example implementation.},
	language = {en},
	urldate = {2018-11-30},
	publisher = {Packt Publishing},
	author = {Simmonds, Chris},
	year = {2017},
	note = {OCLC: 1005013039}
}

@article{doyle_embedded_nodate,
	title = {Embedded {Linux} {Then} and {Now} at {iRobot}},
	language = {en},
	author = {Doyle, Patrick},
	pages = {16}
}

@article{raj_gcc/clang_nodate,
	title = {{GCC}/{Clang} {Optimizations} for {Embedded} {Linux}},
	language = {en},
	author = {Raj, Khem},
	pages = {20}
}

@article{hausherr_design_nodate,
	title = {Design for {Manufacturability} of {Rigid} {Multi}-{Layer} {Boards}},
	language = {en},
	author = {Hausherr, Tom},
	pages = {91}
}

@article{downey_how_nodate,
	title = {How to think like a computer scientist},
	language = {en},
	author = {Downey, Allen B},
	pages = {191}
}

@article{wang_cubemapslam:_2018,
	title = {{CubemapSLAM}: {A} {Piecewise}-{Pinhole} {Monocular} {Fisheye} {SLAM} {System}},
	shorttitle = {{CubemapSLAM}},
	url = {http://arxiv.org/abs/1811.12633},
	abstract = {We present a real-time feature-based SLAM (Simultaneous Localization and Mapping) system for fisheye cameras featured by a large field-of-view (FoV). Large FoV cameras are beneficial for large-scale outdoor SLAM applications, because they increase visual overlap between consecutive frames and capture more pixels belonging to the static parts of the environment. However, current feature-based SLAM systems such as PTAM and ORB-SLAM limit their camera model to pinhole only. To compensate for the vacancy, we propose a novel SLAM system with the cubemap model that utilizes the full FoV without introducing distortion from the fisheye lens, which greatly benefits the feature matching pipeline. In the initialization and point triangulation stages, we adopt a unified vector-based representation to efficiently handle matches across multiple faces, and based on this representation we propose and analyze a novel inlier checking metric. In the optimization stage, we design and test a novel multi-pinhole reprojection error metric that outperforms other metrics by a large margin. We evaluate our system comprehensively on a public dataset as well as a self-collected dataset that contains real-world challenging sequences. The results suggest that our system is more robust and accurate than other feature-based fisheye SLAM approaches. The CubemapSLAM system has been released into the public domain.},
	urldate = {2018-12-03},
	journal = {arXiv:1811.12633 [cs]},
	author = {Wang, Yahui and Cai, Shaojun and Li, Shi-Jie and Liu, Yun and Guo, Yangyan and Li, Tao and Cheng, Ming-Ming},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.12633},
	keywords = {Computer Science - Robotics}
}

@article{guo_local_2018,
	title = {Local {Descriptor} for {Robust} {Place} {Recognition} using {LiDAR} {Intensity}},
	url = {http://arxiv.org/abs/1811.12646},
	abstract = {Place recognition is a challenging problem in mobile robotics, especially in unstructured environments or under viewpoint and illumination changes. Most LiDAR-based methods rely on geometrical features to overcome such challenges, as generally scene geometry is invariant to these changes, but tend to affect camera-based solutions significantly. Compared to cameras, however, LiDARs lack the strong and descriptive appearance information that imaging can provide. To combine the benefits of geometry and appearance, we propose coupling the conventional geometric information from the LiDAR with its calibrated intensity return. This strategy extracts extremely useful information in the form of a new descriptor design, coined ISHOT, outperforming popular state-of-art geometric-only descriptors by significant margin in our local descriptor evaluation. To complete the framework, we furthermore develop a probabilistic keypoint voting place recognition algorithm, leveraging the new descriptor and yielding sublinear place recognition performance. The efficacy of our approach is validated in challenging global localization experiments in large-scale built-up and unstructured environments.},
	urldate = {2018-12-03},
	journal = {arXiv:1811.12646 [cs]},
	author = {Guo, Jiadong and Borges, Paulo V. K. and Park, Chanoh and Gawel, Abel},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.12646},
	keywords = {Computer Science - Robotics}
}

@article{therkelsen_analysis_1954,
	title = {Analysis of the suspension system of the {M}47 tank by means of simulation techniques},
	author = {Therkelsen, EB and Garelis, C and Geyer, VH},
	year = {1954}
}

@article{allen_models_nodate,
	title = {Models for the {Dynamic} {Simulation} of {Tank} {Track} {Components}},
	abstract = {This project has been sponsored by QinetiQ Limited (QinetiQ); whose aim it is to model the dynamics of a prototype high-speed military tracked vehicle. Specifically their objective is to describe the mechanism by which force inputs are transmitted from the ground to the vehicle’s hull.},
	language = {en},
	author = {Allen, Paul},
	pages = {193}
}

@article{kciuk_modelling_2010,
	title = {{MODELLING} {OF} {TRACKED} {VEHICLE} {DYNAMICS}},
	volume = {17},
	number = {1},
	journal = {Journal of KONES Powertrain and Transport},
	author = {Kciuk, Sławomir and MĊżyk, Arkadiusz and Mura, Gabriel},
	year = {2010}
}

@article{switonski_modelling_2011,
	title = {Modelling and {Investigation} of {Dynamic} {Parameters} of {Tracked} {Vehicles}},
	volume = {15},
	number = {4},
	journal = {Mechanics and Mechanical Engineering},
	author = {Switonski, Eugeniusz and lawomir Kciuk, S and Klein, Wojciech},
	year = {2011},
	pages = {115--130}
}

@article{miller_battery_2011,
	title = {Battery {Firmware} {Hacking}},
	author = {Miller, Charlie},
	year = {2011}
}

@inproceedings{nguyen_robotics_2001,
	title = {Robotics for law enforcement: applications beyond explosive ordnance disposal},
	volume = {4232},
	shorttitle = {Robotics for law enforcement},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/4232/0000/Robotics-for-law-enforcement-applications-beyond-explosive-ordnance-disposal/10.1117/12.417561.short},
	doi = {10.1117/12.417561},
	abstract = {We conducted a web-based survey to establish law enforcement robotics needs for applications that extend beyond explosive ordnance disposal. The survey addressed scenarios and tasks where a robot would be used if available, and the tools, features and parameters deemed most important to carry out those tasks. We present in this paper the results of the survey and summarize current robotics research and development efforts by various segments of the Department of Defense that could potentially help meet those law enforcement needs. We also provide a recommended course of action to the Department of Justice for the development of these robotics capabilities.},
	urldate = {2018-12-09},
	booktitle = {Enabling {Technologies} for {Law} {Enforcement} and {Security}},
	publisher = {International Society for Optics and Photonics},
	author = {Nguyen, Hoa G. and Bott, John P.},
	month = feb,
	year = {2001},
	pages = {433--455}
}

@techreport{nguyen_robotic_1998,
	title = {Robotic {Systems}},
	url = {https://apps.dtic.mil/docs/citations/ADA537598},
	abstract = {Teleoperated platforms being introduced into the field are expected to assume a larger role in the access and neutralization of area denial and explosive devices. This work includes examination, identification, and disposal of ordnance. These manipulators that consist of a base platform and a multiple degree of freedom manipulator with end effector get carried to the work site by vehicles. Current commercial and developmental arms are either too expensive for EOD use or do not have the flexibility and strength-to-weight ratio necessary for Render Safe Procedures (RSPs). Technologies that lead to serpentine manipulators and electrostrictive polymer (ESP) actuators will be explored in this effort. Manipulators using these technologies would provide the operator, who is out of harms way, with high dexterity, which makes it valuable for complex and obstructed environments that are often encountered. The key to development of the manipulator is a new actuation technology, an ESP artificial muscle that has been developed at SRI. Muscle-like actuators based on this technology have the combination of high force-to-weight ratio, large stroke capability, good speed of response, and high efficiency unavailable in other actuation technologies. The use of such actuators will allow for the development of an extremely lightweight and slender manipulator with a sufficient number of degrees of freedom to negotiate motion around obstacles. Manipulators using these actuators are expected to be inexpensive, efficient, and reliable. Our objective is to develop this technology to the point that a highly dexterous serpentine manipulator with a follow the leader control methodology can be realized for EOD access missions.},
	language = {en},
	urldate = {2018-12-09},
	institution = {NAVAL EXPLOSIVE ORDNANCE DISPOSAL TECHNOLOGY DIV INDIAN HEAD MD},
	author = {Nguyen, Tuan B. and Greene, Mike and Willett, Jesse A. and Kornbluh, Roy D.},
	month = sep,
	year = {1998}
}

@inproceedings{czop_low-cost_2005,
	title = {Low-cost explosive ordnance disposal robot using off-the-shelf parts},
	volume = {5804},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/5804/0000/Low-cost-explosive-ordnance-disposal-robot-using-off-the-shelf/10.1117/12.602526.short},
	doi = {10.1117/12.602526},
	abstract = {The continuing military operations in Iraq and Afghanistan have resulted in a rapidly growing demand for mobile robots to be used during Explosive Ordnance Disposal operations. These robots are predominately used by EOD technicians for surveillance and neutralization of explosive threats from a safe standoff distance. The hazardous nature of the mission these vehicles help perform requires them to be expendable. Current commercially available systems, however, although capable of performing the mission, are costly and are not currently available in the large quantities needed by EOD technicians. The Naval EOD Technology Division (NAVEODTECHDIV) proposes an alternative; a low cost, mobile robot using Commercial Off-The-Shelf (COTS) parts that is specifically tailored to perform hazardous EOD missions. The main functions of this robot are efficient surveillance and explosive threat neutralization. The use of COTS parts allows for streamlined field supportability and repair. A proposed speed of five miles per hour is a drastic improvement over many existing EOD robots and will allow EOD teams to quickly survey and assess potentially dangerous situations. The manipulator will be capable of precision placement of neutralization charges. The cost of this proposed robot is \$10,000. Current commercial robots capable of performing these EOD tasks range in price from \$40,000 to over \$150,000. This conference paper will describe the robot design and prototyping process, from gathering requirements to fabrication and testing.},
	urldate = {2018-12-09},
	booktitle = {Unmanned {Ground} {Vehicle} {Technology} {VII}},
	publisher = {International Society for Optics and Photonics},
	author = {Czop, Andrew and Hacker, Kurt and Murphy, James and Zimmerman, Todd},
	month = may,
	year = {2005},
	pages = {130--141}
}

@article{kececi_completely_2009,
	title = {Completely mechanical quick changeable joints for multipurpose explosive ordnance disposal robots},
	volume = {27},
	issn = {1469-8668, 0263-5747},
	url = {https://www.cambridge.org/core/journals/robotica/article/completely-mechanical-quick-changeable-joints-for-multipurpose-explosive-ordnance-disposal-robots/687B9E7B4C0476B14BC6156FF8B23AED},
	doi = {10.1017/S0263574708004943},
	abstract = {This paper is an investigation of completely mechanical quick changeable joints for multipurpose explosive ordnance disposal (EOD) robots. With the assistance of a quick changeable joint, an ordinary EOD robot becomes a multipurpose robot with an end effector which can be switched during the task. This exchangeable end effector permits the robot to perform more complex duties. Making the joint completely mechanical increases its capacity and decreases its complexity of control and risk of failure. In this paper, the design, manufacturing, and testing stages are explained for four quick changeable joints each possessing different physical working principles. The test results reveal the best design for a multipurpose EOD robot and give ideas for other uses of quick changeable joints. Employing the quick changeable joints in other mobile robot applications can increase a robot's capacity and efficiency.},
	language = {en},
	number = {4},
	urldate = {2018-12-09},
	journal = {Robotica},
	author = {Kececi, E. Faruk},
	month = jul,
	year = {2009},
	keywords = {Joint testing, Multipurpose robot, Quick changeable joint},
	pages = {555--565}
}

@inproceedings{m._w._carey_novel_2012,
	title = {Novel {EOD} robot design with dexterous gripper and intuitive teleoperation},
	isbn = {2154-4824},
	booktitle = {World {Automation} {Congress} 2012},
	author = {{M. W. Carey} and {E. M. Kurz} and {J. D. Matte} and {T. D. Perrault} and {T. Padir}},
	month = jun,
	year = {2012},
	keywords = {Cameras, Robot vision systems, Robot kinematics, Explosives, Grippers},
	pages = {1--6}
}

@article{eads_training_nodate,
	title = {Training {Simulation} of the {Manipulator} {Vehicle} {tEODor} for {Explosive} {Ordnance} {Disposal} ({EOD}) and {Improvised} {Explosive} {Device} {Disposal} ({IEDD})},
	abstract = {The simulation of manipulator vehicles is a challenge in the ﬁeld of EOD and IED disposal training. The focus in such vehicle simulations is to reproduce the behavior of the vehicle in terms of control and movement and also to simulate interactions with the environment in order to prepare the user for real operations.},
	language = {en},
	author = {Eads, Wolfram Schoor},
	pages = {14}
}

@inproceedings{kruckel_intuitive_2015,
	title = {Intuitive visual teleoperation for {UGVs} using free-look augmented reality displays},
	doi = {10.1109/ICRA.2015.7139809},
	abstract = {For numerous real-world applications teleoperated unmanned guided vehicles (UGVs) can quite successfully assist a human in fulfilling her mission objectives. It is important for the specialists to get an overview of the site quickly and with as intuitive means as possible. Our approach to an intuitive human-machine interface for visually teleoperating UGVs makes use of a spherical camera in combination with the Virtual Reality Head-Mounted Display (HMD) Oculus Rift. The Oculus Rift is equipped with an inertial measurement unit to track the teleoperator's head orientation. With this orientation information, the current field of view is synthesized from the panoramic image coming from the spherical camera allowing a free look for the operator. In this paper, we present the hardware setup and the software system of our free-look HMD approach on our UGV. Our approach allows for multi-view, i.e, several operators can collaborate on a given task. What is more, we augment the spherical image with heading and orientation information of the robot as well as of other viewers. Our preliminary evaluation with a number of untrained user suggests that our free-look HMD offers an intuitive multi-view human-machine interface for teleoperating UGVs.},
	booktitle = {2015 {IEEE} {International} {Conference} on {Robotics} and {Automation} ({ICRA})},
	author = {Krückel, K. and Nolden, F. and Ferrein, A. and Scholl, I.},
	month = may,
	year = {2015},
	keywords = {Cameras, Robot vision systems, augmented reality, control engineering computing, free-look augmented reality displays, free-look HMD approach, hardware setup, head orientation, inertial measurement, intuitive visual teleoperation, man-machine systems, mission objectives, multiview human-machine interface, oculus rift, orientation information, panoramic image, remotely operated vehicles, software system, spherical camera, Teleoperators, Three-dimensional displays, UGV, unmanned guided vehicles, virtual reality head-mounted display},
	pages = {4412--4417}
}

@techreport{nguyen_maintaining_2004,
	title = {Maintaining {Communications} {Link} for a {Robot} {Operating} in a {Hazardous} {Environment}},
	url = {https://apps.dtic.mil/docs/citations/ADA422021},
	abstract = {We address the problem of maintaining a robust high-bandwidth RF communication link between a mobile robot and its remote control/monitoring station. The solution we are exploring uses a number of autonomous mobile relay nodes. These slave robots convoy behind the teleoperated or autonomous lead robot and automatically stop where needed to maintain an ad hoc network that guarantees a link between the lead robot and its control station. their mobility allows for more versatility in the network. Nodes that are no longer needed in the network have the ability to navigate back to the lead robot, in order to redeploy at a later time. This further extends the lead robot's range. This paper describes the system, strategy, hardware development, software algorithms, and experiments conducted.},
	language = {en},
	urldate = {2018-12-09},
	institution = {SPACE AND NAVAL WARFARE SYSTEMS COMMANDSAN DIEGO CA},
	author = {Nguyen, Hoa G. and Pezeshkian, Narek and Gupta, Anoop and Farrington, Nathan},
	month = mar,
	year = {2004}
}

@inproceedings{liu_track-stair_2008,
	title = {Track-stair and vehicle-manipulator interaction analysis for tracked mobile manipulators climbing stairs},
	doi = {10.1109/COASE.2008.4626420},
	abstract = {This paper analyzes interactions between the tracks and the stairs, as well as those between the tracked mobile robot and the onboard manipulator for tracked mobile manipulators (TMMs) climbing stairs. Combining a tracked mobile robot, which has the ability to climb stairs, with an onboard manipulator, a TMM extends the workspace and scope of applications of the robot dramatically. However, this combination gives rise to complex track-stair and vehicle-manipulator interactions, because the configuration of the onboard manipulator affects load distribution, which will further influence the track-stair interactive forces. Unlike the wheeled mobile robots, which are normally assumed to obey the nonholonomic constraints, slippage is unavoidable for a tracked mobile robot, especially when climbing stairs. The track-stair interactive forces are complicated, which may take the forms of grouser-tread hooking force, track-stair edge frictional force, grouser-riser clutching force, and even their compositions. In this paper, the track-stair and vehicle-manipulator interactions are analyzed systematically, which are essential for tip-over prediction and prevention, as well as for automatic control of TMMs in autonomous and semi-autonomous stair-climbing. Simulations for a TMM being developed in our laboratory have demonstrated the usefulness of the presented analysis results.},
	booktitle = {2008 {IEEE} {International} {Conference} on {Automation} {Science} and {Engineering}},
	author = {Liu, Yugang and Liu, Guangjun},
	month = aug,
	year = {2008},
	keywords = {Automation, mobile robots, tip-over prevention, automatic control, Bridges, Conferences, grouser-riser clutching force, grouser-tread hooking force, load distribution, manipulator kinematics, manipulators, nonholonomic constraints, onboard manipulator, slippage, tip-over prediction, track-stair edge frictional force, track-stair interactive forces, tracked mobile manipulators climbing stairs, USA Councils, vehicle-manipulator interaction analysis},
	pages = {157--162}
}

@inproceedings{massey_improved_2009,
	title = {Improved situational awareness and mission performance for explosive ordnance disposal robots},
	volume = {7332},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/7332/73320O/Improved-situational-awareness-and-mission-performance-for-explosive-ordnance-disposal/10.1117/12.820188.short},
	doi = {10.1117/12.820188},
	abstract = {The operator's situational awareness greatly affects mission performance for remote operations of Explosive Ordnance Disposal (EOD) robots. Testing by Army EOD sergeants has shown that a Head-Aimed Remote Viewer (HARV) can significantly increase mission performance in several key tasks, such as identifying secondary Improvised Explosive Devices (IED's) and maneuvering in tight quarters. A HARV system improves the operator's situational awareness by providing an intuitive, "look around" vision interface that DARPA research4 has shown provides a 400\% improvement in the operator's spatial understanding of the remote environment. This paper describes the results of functional testing conducted by US Army civilian engineers and EOD sergeants at Picatinny Arsenal, in support of W15QKN-06-C-0190.},
	urldate = {2018-12-09},
	booktitle = {Unmanned {Systems} {Technology} {XI}},
	publisher = {International Society for Optics and Photonics},
	author = {Massey, Kent and Sapp, Jared and Tsui, Eddy},
	month = 04,
	year = {2009},
	pages = {73320O}
}

@inproceedings{mo_study_2006,
	title = {Study on dynamic stability of a tracked robot climbing over an obstacle or descending stairs},
	doi = {10.1109/DELTA.2006.81},
	abstract = {Tracked mobile robot is popular used in hazardous environments, such as explosives disposal, or removal of dangers. Usually, they work in complex environments and need to cross over different obstacles to reach destination. In this status, the stability and security is very important. In this paper, the dynamic stability of a tracked robot crossing obstacle and up/down stairs is analyzed. The factor of influencing the robot stability is obtained by establishing kinematics and dynamics equations. Two parameters, the maximum angular velocity and the additional front rake, are suggested to be used to describing the status of the robot on stairs. According the results of analysis, the angular velocity is larger, the additional front rake is larger too, resulting in a rather larger impulse between the robot and the stairs, and even falling down the stairs},
	booktitle = {Third {IEEE} {International} {Workshop} on {Electronic} {Design}, {Test} and {Applications} ({DELTA}'06)},
	author = {Mo, Haijun and Huang, Ping and Wu, Shaowei},
	month = jan,
	year = {2006},
	keywords = {Mobile robots, Mechanical engineering, mobile robots, Robot sensing systems, Kinematics, Explosives, Angular velocity, collision avoidance, dynamic equations, dynamic stability, Educational institutions, Equations, explosives disposal, kinematic equations, maximum angular velocity, robot kinematics, robot stability, Security, stability, Stability, tracked mobile robot},
	pages = {4 pp.--213}
}

@inproceedings{reichard_design_2008,
	title = {Design and development of a family of explosive ordnance disposal ({EOD}) robots},
	volume = {7112},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/7112/711212/Design-and-development-of-a-family-of-explosive-ordnance-disposal/10.1117/12.802606.short},
	doi = {10.1117/12.802606},
	abstract = {Across many consumer product industries, the prevailing practice is to design families of product variants that exploit commonality to provide the ability to easily customize a base platform for particular uses and to take advantage of commonality for streamlining design, manufacturing, maintenance and logistic; examples include Black \& Decker, Seagate, and Volkswagen. This paper describes the application of product family concepts to the design and development of a family of robots to satisfy requirements for explosive ordnance disposal. To facilitate this process, we have developed a market segmentation grid that plots the desired capabilities and cost versus the target use cases. The product family design trade space is presented using a multi-dimensional trade space visualization tool which helps identify dependencies between different design variables and identify Pareto frontiers along which optimal design choices will lie. The EOD robot product family designs share common components and subsystems yet are modularized and scalable to provide functionality to satisfy a range of user requirements. This approach has been shown to significantly reduce development time and costs, manufacturing costs, maintenance and spare parts inventory, and operator and maintainer training.},
	urldate = {2018-12-09},
	booktitle = {Unmanned/{Unattended} {Sensors} and {Sensor} {Networks} {V}},
	publisher = {International Society for Optics and Photonics},
	author = {Reichard, Karl and Simpson, Tim and Rogan, Chris and Merenich, John and Brennan, Sean and Crow, Ed},
	month = oct,
	year = {2008},
	pages = {711212}
}

@techreport{noauthor_robocup_nodate-1,
	title = {{RoboCup} {Rescue} {Rulebook} 2019},
	language = {English},
	institution = {RoboCup}
}

@article{eldoled_why_nodate,
	title = {Why you need dimming curves},
	language = {en},
	author = {{eldoLED}},
	pages = {5}
}

@article{palmarini_reverse_2015,
	title = {Reverse {Engineering} {Of} {Embedded} {Architectures}},
	url = {http://dspace.unive.it/handle/10579/5762},
	abstract = {There exists multiple definitions of embedded device and architecture: generally speaking, an embedded device is an object that contains a special-purpose computing system. These devices can be found in many security critical environments such as car's anti-lock breaking systems, medical devices (eg. cardio machines, defibrillators) and even aircraft's avionics. The arrival of the so-called Internet of Things will connect many devices to the web, exposing all the potential security vulnerabilities. The process of studying the implementation of a device to understand its design is known as reverse engineering. In this thesis we present a detailed analysis of attack vectors and techniques adopted in the field of reverse engineering of embedded devices. To try to overcome security shortcomings of production devices, we will present advices and design practices of embedded architecture's common features such as inter-device communication and software updates.},
	urldate = {2019-02-09},
	author = {Palmarini, Francesco {\textless}1986{\textgreater}},
	month = mar,
	year = {2015}
}

@book{lehmann_variant-flexible_2016,
	title = {A variant-flexible assembly cell for hydraulic valve sections using a sensitive lightweight robot},
	author = {Lehmann, Christian and Philipp Städter, J and Wächter, Kornelius},
	month = jun,
	year = {2016}
}

@inproceedings{hernandez-mendez_design_2017,
	address = {Ixtapa, Mexico},
	title = {Design and implementation of a robotic arm using {ROS} and {MoveIt}!},
	isbn = {978-1-5386-0819-7},
	url = {http://ieeexplore.ieee.org/document/8261666/},
	doi = {10.1109/ROPEC.2017.8261666},
	abstract = {In this paper is presented an interfacing of a robotic arm with a motion planner and a 3D viewer (RViz). The main purpose of this work, is to manipulate and grip objects to transport them from one location to another using Robot Operating System (ROS). In order to do this task, a motion planner, who deal with constraints, i.e. collisions among the arm joints and objects, is used. Also a 3D viewer, called RViz, is used to visualize (online and ofﬂine) the motion of the arm. To easily interface the 3 degree of freedom (DOF) arm, it was designed using FreeCAD, as the output ﬁles used to print the arm, are simultaneously exported to create the Uniﬁed Robot Description Format (URDF) ﬁles required for the planner and viewer. A position-force controller for the gripper, previously presented, has been used to pick up and hold the object during the manipulation. Some experiments where carried out to asses the result of the interface, the execution of the motion planning avoiding collision and the grasp to the object. These results are shown and discussed.},
	language = {en},
	urldate = {2019-05-07},
	booktitle = {2017 {IEEE} {International} {Autumn} {Meeting} on {Power}, {Electronics} and {Computing} ({ROPEC})},
	publisher = {IEEE},
	author = {Hernandez-Mendez, Sergio and Maldonado-Mendez, Carolina and Marin-Hernandez, Antonio and Rios-Figueroa, Homero Vladimir and Vazquez-Leal, Hector and Palacios-Hernandez, Elvia R.},
	month = nov,
	year = {2017},
	pages = {1--6}
}

@article{laurenzi_cartesi/o:_nodate,
	title = {{CartesI}/{O}: {A} {ROS} {Based} {Real}-{Time} {Capable} {Cartesian} {Control} {Framework}},
	abstract = {This work introduces a framework for the Cartesian control of multi-legged, highly redundant robots. The proposed framework allows the untrained user to perform complex motion tasks with robotics platforms by leveraging a simple, auto-generated ROS-based interface. Contrary to other motion control frameworks (e.g. ROS MoveIt!), we focus on the execution of Cartesian trajectories that are speciﬁed online, rather than planned in advance, as it is the case, for instance, in tele-operation and locomotion tasks. Moreover, we address the problem of generating such motions within a hard realtime (RT) control loop. Finally, we demonstrate the capabilities of our framework both on the COMAN+ humanoid robot, and on the hybrid wheeled-legged quadruped CENTAURO.},
	language = {en},
	author = {Laurenzi, Arturo and Hoffman, Enrico and Muratore, Luca and Tsagarakis, Nikos},
	pages = {8}
}

@article{gao_implementation_2018,
	title = {Implementation of open-architecture kinematic controller for articulated robots under {ROS}},
	volume = {45},
	issn = {0143-991X},
	url = {https://www.emeraldinsight.com/doi/10.1108/IR-09-2017-0166},
	doi = {10.1108/IR-09-2017-0166},
	abstract = {Purpose – This paper aims to present an open-architecture kinematic controller, which was developed for articulated robots, facing the demands of various applications and low cost on robot system. Design/methodology/approach – A general approach to develop this controller is described in hardware and software design. The hardware consists of embedded boards and programable multi-axes controller (PMAC), connected with ethernet, and the software is implemented on a robot operating system with MoveIt!. The authors also developed a teach pendant running as a LAN node to provide a human–machine interface (HMI).},
	language = {en},
	number = {2},
	urldate = {2019-07-15},
	journal = {Industrial Robot: An International Journal},
	author = {Gao, Yongzhuo and Du, Zhijiang and Gao, Xueshan and Su, Yanyu and Mu, Yu and Sun, Li Ning and Dong, Wei},
	month = mar,
	year = {2018},
	pages = {244--254}
}

@misc{noauthor_robot_nodate-1,
	title = {Robot {Joystick} to {Differential} {Steering} - {ImpulseAdventure}},
	url = {https://www.impulseadventure.com/elec/robot-differential-steering.html},
	urldate = {2019-07-28}
}

@inproceedings{gehring_navigation_2010,
	title = {Navigation on an implicit {Voronoı}̈ diagram : experimental evaluation and implementation issues},
	shorttitle = {Navigation on an implicit {Voronoı}̈ diagram},
	abstract = {Obstacle avoidance and safe exploration are very important subjects in autonomous mobile robotics and cornerstones for most high level control algorithms. Victorino et al. introduced in [6] a powerful navigation strategy especially for small robots when low computational effort is an issue. The approach does not need to calculate the Voronoı̈ graph explicitly and does not require any a-priori knowledge of a map. The sensor-based control framework depends only on laser scans and includes obstacle avoidance by its nature of design. In this paper we show an implementation of their work on a real world platform and discuss the problems we encountered. Moreover we show some additional approaches needed to complete the safe navigation task and discuss our results obtained in simulations as well as in real world environments.},
	author = {Gehring, Christian and Pilat, Yves and Pradalier, Cédric and Pomerleau, François and Siegwart, Roland},
	year = {2010},
	keywords = {Robotics, Algorithm, Autonomous robot, High-level programming language, Mobile robot, Obstacle avoidance, Simulation, Voronoi diagram}
}

@article{sainul_automatic_2019,
	title = {Automatic pre-grasps generation for unknown 3D objects},
	url = {http://arxiv.org/abs/1908.00221},
	abstract = {In this paper, the problem of automating the pre-grasps generation for novel 3d objects has been discussed. The objects represented as cloud of 3D points are split into parts and organized in a tree structure, where parts are approximated by simple box primitives. Applying grasping only on the individual object parts may miss a good grasp which involves a combination of parts. The problem has been addressed by traversing the decomposition tree and checking each node of the tree for possible pre-grasps against a set of conditions. Further, a face mask has been introduced to encode the free and blocked faces of the box primitives. Pre-grasps are generated only for the free faces. Finally, the proposed method implemented on a set twenty-four household objects and toys, where a grasp planner based on object slicing method has been used to compute the contact-level grasp plan.},
	urldate = {2019-08-02},
	journal = {arXiv:1908.00221 [cs]},
	author = {Sainul, I. A. and Deb, Sankha and Deb, A. K.},
	month = aug,
	year = {2019},
	note = {arXiv: 1908.00221},
	keywords = {Computer Science - Robotics, Computer Science - Computational Geometry}
}

@article{mirowski_probabilistic_2014,
	title = {Probabilistic radio-frequency fingerprinting and localization on the run},
	volume = {18},
	issn = {1538-7305},
	doi = {10.1002/bltj.21649},
	abstract = {Indoor localization is a key enabler for pervasive computing and network optimization. Wireless local area network (WLAN) positioning systems typically rely on fingerprints of received signal strength (RSS) measures from access points. In this paper, we review approaches for modeling full distributions of Wi-Fi signals, including Bayesian graphical models, smoothing, compressive sensing, and random field differentiation and concentrate on the Kullback-Leibler divergence metric that compares multivariate RSS distributions. We provide theoretical insights on the required spatial density of fingerprints and on the number of samples necessary, during tracking or during signal map building, to differentiate among signal distributions and to provide accurate location estimates. We validate our methods on contrasting datasets where we obtain state-of-the-art localization results. Finally, we exploit datasets collected by a self-localizing mobile robot that continuously records Wi-Fi along with ground truth position, where we define increasingly denser fingerprint grids and study asymptotic localization accuracy. ® 2014 Alcatel-Lucent.},
	number = {4},
	journal = {Bell Labs Technical Journal},
	author = {Mirowski, P. and Milioris, D. and Whiting, P. and Ho, T. K.},
	month = mar,
	year = {2014},
	keywords = {Mobile robots, Area measurement, Data analysis, Fingerprint recognition, IEEE 802.11 Standards, Indoor communication, Localization, Pervasive computing, Position measurement, Wireless LAN},
	pages = {111--133}
}

@incollection{goswami_differential_2019,
	address = {Dordrecht},
	title = {Differential {Kinematics}},
	isbn = {978-94-007-6045-5 978-94-007-6046-2},
	url = {http://link.springer.com/10.1007/978-94-007-6046-2_2},
	abstract = {Kinematics play an essential role in motion analysis, motion generation, and control. This chapter focuses on the differential kinematic relations pertinent to open-loop and closed-loop kinematic chains. It is assumed that readers are familiar with the basic concepts concerning systems of rigid bodies, such as representations of positions and orientations, the kinematics of joints, coordinate frame assignment techniques for serial-link and parallel-link mechanisms, coordinate transformations, and the forward and inverse kinematic problems. First, the role of differential kinematics for instantaneous motion analysis is highlighted. The forward and inverse differential kinematic problems for open-loop systems are then formulated using ﬁrst-order (velocity level) and second-order (acceleration level) relationships. Further on, instantaneous motion analysis and methods for motion generation at special (singular) conﬁgurations are discussed. Generic singular conﬁgurations for humanoid robots with and without kinematically redundant limbs are highlighted, and the notion of manipulability ellipsoid is introduced. Special attention is paid to solutions to the inverse instantaneous motion problem for kinematic chains with kinematic redundancy. Two basic cases are discussed for redundancy pertinent to a single limb and the whole-body chain. In the latter case, solution methods for multipletask constraints are highlighted, covering both ﬁxed and variable-priority tasks within a hierarchical structure. Finally, differential kinematic relations within chains with motion constraints stemming from contacts with the environment are derived.},
	language = {en},
	urldate = {2019-08-13},
	booktitle = {Humanoid {Robotics}: {A} {Reference}},
	publisher = {Springer Netherlands},
	author = {Nenchev, Dragomir},
	editor = {Goswami, Ambarish and Vadakkepat, Prahlad},
	year = {2019},
	doi = {10.1007/978-94-007-6046-2_2},
	pages = {675--721}
}

@techreport{maximilian_ritter_further_nodate,
	title = {Further development of an open-source thermal imaging system in terms of hardware, software and performance optimizations},
	author = {{Maximilian Ritter}}
}

@article{arathorn_technical_2019,
	title = {Technical {Report}: {Fast} {Robot} {Arm} {Inverse} {Kinematics} and {Path} {Planning} {Under} {Complex} {Obstacle} {Constraint}},
	shorttitle = {Technical {Report}},
	url = {http://arxiv.org/abs/1906.10678},
	abstract = {Described here is a simple, reliable method for rapid computation of robot arm inverse kinematic solutions and motion path plans in the presence of complex obstructions. The method is based on a restricted form of the MSC (map-seeking circuit) algorithm, optimized to exploit the characteristics of practical arm configurations. MSC representation naturally incorporates both arm and obstacle geometries. The consequent performance on modern hardware is suitable for applications requiring real-time response. On high-end GPGPU hardware computation of both final pose for an 8 DOF arm and a smooth obstacle-avoiding motion path to that pose takes approximately 200msec.},
	urldate = {2019-09-04},
	journal = {arXiv:1906.10678 [cs]},
	author = {Arathorn, David W.},
	month = jun,
	year = {2019},
	note = {arXiv: 1906.10678},
	keywords = {Computer Science - Robotics, Computer Science - Computer Vision and Pattern Recognition}
}

@article{amigoni_standard_2018,
	title = {A {Standard} for {Map} {Data} {Representation}: {IEEE} 1873-2015 {Facilitates} {Interoperability} {Between} {Robots}},
	volume = {25},
	issn = {1070-9932, 1558-223X},
	shorttitle = {A {Standard} for {Map} {Data} {Representation}},
	url = {https://ieeexplore.ieee.org/document/8259474/},
	doi = {10.1109/MRA.2017.2746179},
	language = {en},
	number = {1},
	urldate = {2019-11-06},
	journal = {IEEE Robotics \& Automation Magazine},
	author = {Amigoni, Francesco and Yu, Wonpil and Andre, Torsten and Holz, Dirk and Magnusson, Martin and Matteucci, Matteo and Moon, Hyungpil and Yokotsuka, Masashi and Biggs, Geoffrey and Madhavan, Raj},
	month = mar,
	year = {2018},
	pages = {65--76}
}

@article{kohlbrecher_holistic_nodate,
	title = {A {Holistic} {Approach} for {Highly} {Versatile} {Supervised} {Autonomous} {Urban} {Search} and {Rescue} {Robots}},
	author = {Kohlbrecher, Stefan},
	pages = {143}
}

@article{dyck_mobile_nodate,
	title = {Mobile {Rescue} {Robot} based on {RoboCup} {Rescue} ({NIST}) {Standards}},
	abstract = {This report describes the design and implementation of a mobile rescue robot based on the requirements of the international RoboCup Rescue competition. Mechanically, the robot is heavily inﬂuenced by the widely used military-style tracked Packbot design. However, our focus was primarily on the electrical and control aspects of the design. The main subsystems include: chassis and mechanical design batteries and power system, motors and motion control, hard real-time control, soft real-time control, and the operator station. The project itself followed a three-stage iterative design process: research and scope deﬁnition for each subsystem, individual design, implementation, and testing, and ﬁnally system integration and performance testing. While the ﬁnal product is currently mechanically unsuitable for competition, a solid foundation has been created for subsequent groups to build on. With further design iterations and improvements, speciﬁcally simultaneous localization and mapping (SLAM) integration, increased autonomy with respect to motion control, and mechanical design reﬁnement, it is expected that the robot will be a perennial participant in future RoboCup Rescue events. Ultimately the hope is that this will foster a heightened interest in robotics among engineering students at the University of Manitoba and throughout Canada.},
	language = {en},
	author = {Dyck, Justin and Greenberg, Josh and Sitter, Morgan and Ethier, Joseph and Nemeth, Craig},
	pages = {93}
}

@article{manerikar_slam-assisted_2018,
	title = {{SLAM}-{Assisted} {Coverage} {Path} {Planning} for {Indoor} {LiDAR} {Mapping} {Systems}},
	url = {http://arxiv.org/abs/1811.04825},
	abstract = {Applications involving autonomous navigation and planning of mobile agents can beneﬁt greatly by employing online Simultaneous Localization and Mapping (SLAM) techniques, however, their proper implementation still warrants an efﬁcient amalgamation with any ofﬂine path planning method that may be used for the particular application. In this paper, such a case of amalgamation is considered for a LiDAR-based indoor mapping system which presents itself as a 2D coverage path planning problem implemented along with online SLAM. This paper shows how classic ofﬂine Coverage Path Planning (CPP) can be altered for use with online SLAM by proposing two modiﬁcations: (i) performing convex decomposition of the polygonal coverage area to allow for an arbitrary choice of an initial point while still tracing the shortest coverage path and (ii) using a new approach to stitch together the different cells within the polygonal area to form a continuous coverage path. Furthermore, an alteration to the SLAM operation to suit the coverage path planning strategy is also made that evaluates navigation errors in terms of an area coverage cost function. The implementation results show how the combination of the two modiﬁed ofﬂine and online planning strategies allow for an improvement in the total area coverage by the mapping system - the modiﬁcation thus presents an approach for modifying ofﬂine and online navigation strategies for robust operation.},
	language = {en},
	urldate = {2019-11-19},
	journal = {arXiv:1811.04825 [cs]},
	author = {Manerikar, Ankit and Shamseldin, Tamer and Habib, Ayman},
	month = nov,
	year = {2018},
	note = {arXiv: 1811.04825},
	keywords = {Computer Science - Robotics}
}

@techreport{f45_committee_standard_nodate,
	title = {Standard {Terminology} for {Driverless} {Automatic} {Guided} {Industrial} {Vehicles}},
	url = {http://www.astm.org/cgi-bin/resolver.cgi?F3200-16},
	language = {en},
	urldate = {2019-11-26},
	institution = {ASTM International},
	author = {{F45 Committee}},
	doi = {10.1520/F3200-16}
}

@techreport{f45_committee_practice_nodate,
	title = {Practice for {Recording} {Environmental} {Effects} for {Utilization} with {A}-{UGV} {Test} {Methods}},
	url = {http://www.astm.org/cgi-bin/resolver.cgi?F3218-19},
	language = {en},
	urldate = {2019-11-26},
	institution = {ASTM International},
	author = {{F45 Committee}},
	doi = {10.1520/F3218-19}
}

@article{tang_fast_2015,
	title = {Fast {Fingerprint} {Database} {Maintenance} for {Indoor} {Positioning} {Based} on {UGV} {SLAM}},
	volume = {15},
	issn = {1424-8220},
	url = {http://www.mdpi.com/1424-8220/15/3/5311},
	doi = {10.3390/s150305311},
	language = {en},
	number = {3},
	urldate = {2019-11-26},
	journal = {Sensors},
	author = {Tang, Jian and Chen, Yuwei and Chen, Liang and Liu, Jingbin and Hyyppä, Juha and Kukko, Antero and Kaartinen, Harri and Hyyppä, Hannu and Chen, Ruizhi},
	month = mar,
	year = {2015},
	pages = {5311--5330}
}

@inproceedings{foster_visagge:_2013,
	address = {Karlsruhe, Germany},
	title = {{VisAGGE}: {Visible} angle grid for glass environments},
	isbn = {978-1-4673-5643-5 978-1-4673-5641-1},
	shorttitle = {{VisAGGE}},
	url = {http://ieeexplore.ieee.org/document/6630875/},
	doi = {10.1109/ICRA.2013.6630875},
	abstract = {We describe a new algorithm for occupancy grid mapping using LIDAR in the presence of glass and other nondiffuse surfaces. This is a major problem for robot navigation in many indoor environments due to the prevalence of glass paned doors, windows, and even glass walls, as well as mirrors and polished metal surfaces. Current formulations of occupancy grid mapping make the assumption that objects in the environment are detectable from all angles. However, glass and other specular surfaces are invisible to LIDAR at most angles and so become washed out as “noise”. We modify the standard occupancy grid algorithm to allow for mapping objects that are only visible from certain view angles, by tracking the subset of angles from which objects are reliably visible. We show that these angles can be determined reliably with a single pass through the environment, and that the information can be used to map both diffuse and specular surfaces.},
	language = {en},
	urldate = {2019-11-26},
	booktitle = {2013 {IEEE} {International} {Conference} on {Robotics} and {Automation}},
	publisher = {IEEE},
	author = {Foster, Paul and {Zhenghong Sun} and {Jong Jin Park} and Kuipers, Benjamin},
	month = may,
	year = {2013},
	pages = {2213--2220}
}

@inproceedings{rankin_unmanned_2011,
	address = {Orlando, Florida, United States},
	title = {Unmanned ground vehicle perception using thermal infrared cameras},
	url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.884349},
	doi = {10.1117/12.884349},
	abstract = {The ability to perform off-road autonomous navigation at any time of day or night is a requirement for some unmanned ground vehicle (UGV) programs. Because there are times when it is desirable for military UGVs to operate without emitting strong, detectable electromagnetic signals, a passive only terrain perception mode of operation is also often a requirement. Thermal infrared (TIR) cameras can be used to provide day and night passive terrain perception. TIR cameras have a detector sensitive to either mid-wave infrared (MWIR) radiation (3-5µm) or long-wave infrared (LWIR) radiation (7-14µm). With the recent emergence of high-quality uncooled LWIR cameras, TIR cameras have become viable passive perception options for some UGV programs. The Jet Propulsion Laboratory (JPL) has used a stereo pair of TIR cameras under several UGV programs to perform stereo ranging, terrain mapping, tree-trunk detection, pedestrian detection, negative obstacle detection, and water detection based on object reflections. In addition, we have evaluated stereo range data at a variety of UGV speeds, evaluated dual-band TIR classification of soil, vegetation, and rock terrain types, analyzed 24 hour water and 12 hour mud TIR imagery, and analyzed TIR imagery for hazard detection through smoke. Since TIR cameras do not currently provide the resolution available from megapixel color cameras, a UGV’s daytime safe speed is often reduced when using TIR instead of color cameras. In this paper, we summarize the UGV terrain perception work JPL has performed with TIR cameras over the last decade and describe a calibration target developed by General Dynamics Robotic Systems (GDRS) for TIR cameras and other sensors.},
	language = {en},
	urldate = {2019-11-26},
	author = {Rankin, Arturo and Huertas, Andres and Matthies, Larry and Bajracharya, Max and Assad, Christopher and Brennan, Shane and Bellutta, Paolo and Sherwin, Gary W.},
	editor = {Gage, Douglas W. and Shoemaker, Charles M. and Karlsen, Robert E. and Gerhart, Grant R.},
	month = may,
	year = {2011},
	pages = {804503}
}

@book{okada_shared_2010,
	title = {Shared autonomy system for tracked vehicles to traverse rough terrain based on continuous three-dimensional terrain scanning},
	author = {Okada, Yoshito and Nagatani, Keiji and Yoshida, Kazuya and Yoshida, Tomoaki and Koyanagi, Eiji},
	month = nov,
	year = {2010},
	doi = {10.1109/IROS.2010.5648974},
	keywords = {Flipper control}
}

@inproceedings{m._sokolov_hyperneat-based_2017,
	title = {{HyperNEAT}-based flipper control for a crawler robot motion in 3D simulation environment},
	isbn = {null},
	doi = {10.1109/ROBIO.2017.8324819},
	booktitle = {2017 {IEEE} {International} {Conference} on {Robotics} and {Biomimetics} ({ROBIO})},
	author = {{M. Sokolov} and {I. Afanasyev} and {A. Klimchik} and {N. Mavridis}},
	month = dec,
	year = {2017},
	keywords = {Flipper control},
	pages = {2652--2656}
}

@techreport{filip_sedlacek_autonomous_2012,
	type = {Bachelor's thesis},
	title = {Autonomous fipper control for a tracked robot using 2D vertical laser scan},
	url = {ftp://cmp.felk.cvut.cz/pub/cmp/articles/svoboda/Sedlacek-TR-2012-11.pdf},
	language = {English},
	number = {CTU-CMP-2012-11},
	institution = {Czech Technical University},
	author = {{Filip Sedlacek}},
	month = may,
	year = {2012},
	pages = {59}
}

@techreport{teymur_azayev_deep_2017,
	address = {Prague},
	type = {Master {Thesis}},
	title = {Deep {Learning} for {Autonomous} {Control} of {Robot}’s {Flippers} in {Simulation}},
	language = {English},
	institution = {Czech Technical University},
	author = {{Teymur Azayev}},
	month = jan,
	year = {2017},
	pages = {95}
}

@techreport{robotic_systems_joint_project_office_unmanned_2011,
	title = {Unmanned {Ground} {Systems} {Roadmap}},
	language = {English},
	institution = {Robotic Systems Joint Project Office},
	author = {{Robotic Systems Joint Project Office}},
	month = jun,
	year = {2011},
	pages = {78}
}

@misc{southwest_research_institute_session_2018,
	title = {Session 3: {Motion} {Control} of {Manipulators}},
	language = {English},
	author = {{Southwest Research Institute}},
	month = aug,
	year = {2018}
}

@misc{adolfo_rodriguez_tsouroukdissian_ros_2014,
	title = {{ROS} control, an overview},
	author = {{Adolfo Rodríguez Tsouroukdissian}},
	month = dec,
	year = {2014}
}

@misc{monta_elkins_hacking_2017,
	title = {Hacking firmware where you least expect it: in your tools},
	author = {{Monta Elkins}},
	month = mar,
	year = {2017}
}

@misc{mike_anderson_introduction_2018,
	title = {Introduction to the {Robot} {Operating} {System} {Middleware}},
	url = {https://elinux.org/images/1/11/IntroductionToROS_Anderson.pdf},
	urldate = {2018-12-04},
	author = {{Mike Anderson}},
	month = dec,
	year = {2018}
}

@misc{savoir-faire_linux_embedded_2017,
	title = {Embedded {Linux} system development},
	url = {https://savoirfairelinux.com/fr/formations/unix-linux/EMBD101-Creation-et-gestion-dun-systeme-embarque-fonctionnant-sous-Linux/full-sysdev-slides.pdf},
	urldate = {2018-11-30},
	author = {{Savoir-Faire Linux}},
	month = jul,
	year = {2017}
}